---
title: "Taller_2"
author: GARCIA BERNAL, ZAIRA ALEJANDRA RIVERA SANABRIA, LAURA SARIF JACOME VELASCO,
  NICOLAS VIAFARA MORALES, JORGE ELIECER
date: "2025-03-22"
output: html_document
---

```{r}
#Cargar los paquetes de trabajo
require("pacman")
p_load(tidyverse, # tidy-data
       glmnet, # To implement regularization algorithms. 
       caret, # creating predictive models
       BiocManager,
       Metrics,
       readr,
       utils)

install.packages("MLmetrics") # To calculate metrics
require(MLmetrics)
```

```{r}
## 1. Carga de datos train hogares

# Definir URL del archivo Excel en GitHub
url_excel <- "https://raw.githubusercontent.com/GeorgeWton1986/T2_BDML/refs/heads/main/03_Stores/train_hogares.csv"

# Descargar el archivo temporalmente
temp_file <- tempfile(fileext = ".csv")
GET(url_excel, write_disk(temp_file, overwrite = TRUE))

# Leer el archivo CSV en un dataframe
train_hogares <- read_csv(temp_file)

## 2. Carga de datos train personas

# URL del archivo ZIP en GitHub
url_zip <- "https://github.com/GeorgeWton1986/T2_BDML/raw/refs/heads/main/03_Stores/train_personas.zip"

# Crear un archivo temporal para almacenar el ZIP
temp_zip <- tempfile(fileext = ".zip")

# Descargar el archivo ZIP desde GitHub
GET(url_zip, write_disk(temp_zip, overwrite = TRUE))
temp_dir <- tempfile()
dir.create(temp_dir)

# Extraer el contenido del ZIP
unzip(temp_zip, exdir = temp_dir)

# Leer el archivo CSV extraído
csv_personas1 <- file.path(temp_dir, "train_personas.csv")
train_personas <- read_csv(csv_personas1)

## 3. Carga de datos test hogares

# Definir URL del archivo Excel en GitHub
url_excel_test <- "https://raw.githubusercontent.com/GeorgeWton1986/T2_BDML/refs/heads/main/03_Stores/test_hogares.csv"

# Descargar el archivo temporalmente
temp_file <- tempfile(fileext = ".csv")
GET(url_excel_test, write_disk(temp_file, overwrite = TRUE))

# Leer el archivo CSV en un dataframe
test_hogares <- read_csv(temp_file)

## 4. Carga de datos test personas

# Definir URL del archivo Excel en GitHub
url_excel_test2 <- "https://raw.githubusercontent.com/GeorgeWton1986/T2_BDML/refs/heads/main/03_Stores/test_personas.csv"

# Descargar el archivo temporalmente
temp_file <- tempfile(fileext = ".csv")
GET(url_excel_test2, write_disk(temp_file, overwrite = TRUE))

# Leer el archivo CSV en un dataframe
test_personas <- read_csv(temp_file)
```

#A Train

```{r}
#Asignar y cargar las bases de datos Entrenamiento

train_hogares<-read.csv("C:/Users/njaco/OneDrive/Documentos/Mestría en Economía Aplicada/Semestre 3/Big Data y Machine Learning/train_hogares.csv")
train_personas<-read.csv("C:/Users/njaco/OneDrive/Documentos/Mestría en Economía Aplicada/Semestre 3/Big Data y Machine Learning/train_personas.csv")

```

##A.1 Base Train Hogares

```{r}
#Nombre de las columnas de la base train_hogares
colnames(train_hogares)
```

```{r}
#Seleccion de la columnas id de hogares
train_hogares %>%
  select(id) %>%
  head()
```

```{r}
#Cantidad de hogares probres de la base train_hogares
table(train_hogares$Pobre)
```

```{r}
#Incluir una columna con la asignacion de 1 si el ingreso per capita hogar es menor a la linea de probreza y 0 en caso contrario
train_hogares <- train_hogares %>% 
  mutate(pobre_hand=ifelse(Ingpcug<Lp,1,0))
```

```{r}
#Representación en tabla de los resultado
table(train_hogares$Pobre,train_hogares$pobre_hand)
```

##A.2 Base Train Personas

```{r}
#Nombre de las columnas de la base train_personas

colnames(train_personas)
```

```{r}
#Selección de la columnas id y orden de los mienbros de la base personas
train_personas %>%
  select(id, Orden) %>%
  head()
```

```{r}
#Agrupa las personas por hogar y calculo del indicie de personas inactivas
train_personas_1<- train_personas %>%
  group_by(id)%>%
  summarize(h_inactivos=sum(Ina, na.rm = TRUE),
            h_pet=sum(Pet, na.rm = TRUE))%>%
  mutate(h_inactivosp=h_inactivos/h_pet) %>%
  ungroup()
```

#B Test

```{r}
#Asignar y cargar las bases de datos prueba

test_hogares<-read.csv("C:/Users/njaco/OneDrive/Documentos/Mestría en Economía Aplicada/Semestre 3/Big Data y Machine Learning/test_hogares.csv")
test_personas<-read.csv("C:/Users/njaco/OneDrive/Documentos/Mestría en Economía Aplicada/Semestre 3/Big Data y Machine Learning/test_personas.csv")

```

##B.1 Base Test Hogares

```{r}
#Nombre de las columnas de la base test_hogares

colnames(test_hogares)
```

```{r}
#Selección de la columnas id y número de personas por hogar
test_hogares %>%
  select(id, Npersug) %>%
  head()
```

##B.2 Base Test Personas

```{r}
#Nombre de las columnas de la base test_personas

colnames(test_personas)
```

#1. Pre procesamiento

```{r}
#Pre procesamiento de la base Train_Personas
clear_train_personas <- train_personas %>% 
  mutate(mujer = ifelse(P6020==2,1,0),
  mayor_edad = ifelse(P6040 >= 18,1,0), #Mayores de edad
  H_Head = ifelse(P6050== 1, 1, 0), #Household head
  afi_salud = ifelse (P6090==1,1,0), #Afiliacion de salud
  afi_salud = ifelse (is.na(afi_salud),0,1), #Reemplazo de los NA
  EducLevel = ifelse(P6210==9,0,P6210), #Replace 9 with 0
  EducLevel = ifelse(is.na(EducLevel),0,EducLevel),#Reemplazo de los NA
  act_semana_pasada = ifelse(P6240 == 6,0,P6240),
  act_semana_pasada = ifelse(is.na(act_semana_pasada),0,act_semana_pasada), #Reemplazo de los NA
  t_trab_semanal = ifelse(is.na(P6426),0,1),
  cotizando = ifelse(P6920 == 3, 1, P6920), #Incluir los pensionados
  cotizando = ifelse(is.na(cotizando),0,cotizando),#Reemplazo de los NA
  ocupado = ifelse(is.na(Oc),0,1)) %>%
  select(id, Orden,mujer,mayor_edad,H_Head,afi_salud,EducLevel,act_semana_pasada,t_trab_semanal,cotizando,ocupado)

#Pre procesamiento de la base Test_Personas
clear_test_personas <- test_personas %>% 
  mutate(mujer = ifelse(P6020==2,1,0),
  mayor_edad = ifelse(P6040 >= 18,1,0), #Mayores de edad
  H_Head = ifelse(P6050== 1, 1, 0), #Household head
  afi_salud = ifelse (P6090==1,1,0), #Afiliacion de salud
  afi_salud = ifelse (is.na(afi_salud),0,1), #Reemplazo de los NA
  EducLevel = ifelse(P6210==9,0,P6210), #Replace 9 with 0
  EducLevel = ifelse(is.na(EducLevel),0,EducLevel),#Reemplazo de los NA
  act_semana_pasada = ifelse(P6240 == 6,0,P6240),
  act_semana_pasada = ifelse(is.na(act_semana_pasada),0,act_semana_pasada), #Reemplazo de los NA
  t_trab_semanal = ifelse(is.na(P6426),0,1),
  cotizando = ifelse(P6920 == 3, 1, P6920), #Incluir los pensionados
  cotizando = ifelse(is.na(cotizando),0,cotizando),#Reemplazo de los NA
  ocupado = ifelse(is.na(Oc),0,1)) %>%
  select(id, Orden,mujer,mayor_edad,H_Head,afi_salud,EducLevel,act_semana_pasada,t_trab_semanal,cotizando,ocupado)
```

```{r}
colnames(clear_train_personas)
```

```{r}
colnames(clear_test_personas)
```

##1.2 Argupar y unir Train Personas

```{r}
#Agrupar el entrenamiento de la base personas a nivel hogar y unir las bases de datos por medio de id.

summary_train_personas_nivel_hogar <- clear_train_personas %>% 
  group_by(id) %>% 
  summarize(nmujeres = sum(mujer,na.rm=TRUE),
            nmayor_edad = sum(mayor_edad,na.rm=TRUE),
            nafi_salud = sum(afi_salud, na.rm = TRUE),
            maxEducLevel = max(EducLevel,na.rm=TRUE),
            nt_trab_semanal = sum(t_trab_semanal,na.rm = TRUE),
            ncotizando = sum(cotizando,na.rm = TRUE),
            nocupados=sum(ocupado,na.rm=TRUE))

filter_train_personas_hogar<- clear_train_personas %>% 
                  filter(H_Head==1) %>% 
                  select(id,mujer,afi_salud,EducLevel,cotizando,ocupado) %>% 
                  rename(H_Head_mujer=mujer,
                         H_afi_salud = afi_salud,
                         H_Head_Educ_level=EducLevel,
                         H_cotizando = cotizando,
                         H_Head_ocupado=ocupado) %>% 
                    left_join(summary_train_personas_nivel_hogar)
```

```{r}
colnames(filter_train_personas_hogar)
```

##1.3 Agrupar y unir Test Personas

```{r}
#Agrupar la prueba de la base personas a nivel hogar y unir las bases de datos por medio de id.


summary_test_personas_nivel_hogar <- clear_test_personas %>% 
  group_by(id) %>% 
  summarize(nmujeres = sum(mujer,na.rm=TRUE),
            nmayor_edad = sum(mayor_edad,na.rm=TRUE),
            nafi_salud = sum(afi_salud, na.rm = TRUE),
            maxEducLevel = max(EducLevel,na.rm=TRUE),
            nt_trab_semanal = sum(t_trab_semanal,na.rm = TRUE),
            ncotizando = sum(cotizando,na.rm = TRUE),
            nocupados=sum(ocupado,na.rm=TRUE))

filter_test_personas_hogar<- clear_test_personas %>% 
                  filter(H_Head==1) %>% 
                  select(id,mujer,afi_salud,EducLevel,cotizando,ocupado) %>% 
                  rename(H_Head_mujer=mujer,
                         H_afi_salud = afi_salud,
                         H_Head_Educ_level=EducLevel,
                         H_cotizando = cotizando,
                         H_Head_ocupado=ocupado) %>% 
                    left_join(summary_test_personas_nivel_hogar, by = "id")
```

```{r}
colnames(filter_test_personas_hogar)
```

##1.4 Base de trabajo Train Hogares

```{r}
clear_train_hogares<- train_hogares %>% 
  mutate(pagada= ifelse(P5090==1,1,0),
         hipoteca= ifelse(P5090==2,1,0),
         arriendo= ifelse(P5090==3,1,0),
         usufructo= ifelse(P5090==4,1,0),
         sin_titulo = ifelse(P5090==5,1,0)) %>% 
  select(id, Clase, Nper, Dominio,pagada, hipoteca, arriendo, usufructo, sin_titulo, Lp, Pobre)
```

##1.5 Base de trabajo Test Hogares

```{r}
clear_test_hogares<- test_hogares %>% 
  mutate(pagada= ifelse(P5090==1,1,0),
         hipoteca= ifelse(P5090==2,1,0),
         arriendo= ifelse(P5090==3,1,0),
         usufructo= ifelse(P5090==4,1,0),
         sin_titulo = ifelse(P5090==5,1,0)) %>% 
  select(id, Clase, Nper, Dominio, pagada, hipoteca, arriendo, usufructo, sin_titulo, Lp)
```

##1.6 Consolidar las BD Train y Test Hogares

```{r}
train<- clear_train_hogares %>% 
          left_join(filter_train_personas_hogar) %>% 
          select(-id) #no longer need id

test<- clear_test_hogares %>% 
          left_join(filter_test_personas_hogar)

```

##1.7 Conversion a factores

```{r}
train_factors<- train %>% 
  mutate(Dominio=factor(Dominio),
         pagada=factor(pagada,levels = c(0,1),labels = c("No","Yes")),
         hipoteca=factor(hipoteca,levels = c(0,1),labels = c("No","Yes")),
         arriendo=factor(arriendo,levels = c(0,1),labels = c("No","Yes")),
         usufructo=factor(usufructo,levels = c(0,1),labels = c("No","Yes")),
         sin_titulo=factor(sin_titulo,levels = c(0,1),labels = c("No","Yes")),
         Pobre=factor(Pobre,levels = c(0,1),labels = c("No", "Yes")),
         H_Head_Educ_level = factor(H_Head_Educ_level, levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria')),
         maxEducLevel = factor(maxEducLevel,levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria') ))

test_factors<- test %>% 
  mutate(Dominio=factor(Dominio),
         pagada=factor(pagada,levels = c(0,1),labels = c("No","Yes")),
         hipoteca=factor(hipoteca,levels = c(0,1),labels = c("No","Yes")),
         arriendo=factor(arriendo,levels = c(0,1),labels = c("No","Yes")),
         usufructo=factor(usufructo,levels = c(0,1),labels = c("No","Yes")),
         sin_titulo=factor(sin_titulo,levels = c(0,1),labels = c("No","Yes")),
         H_Head_Educ_level = factor(H_Head_Educ_level, levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria')),
         maxEducLevel = factor(maxEducLevel,levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria') ))

```

#2. Entrenamiento Modelo Elastic Net

##2.1 Modelo Elastic Net

```{r}

ctrl<- trainControl(method = "cv",
                    number = 5,
                    classProbs = TRUE,
                    savePredictions = T)
```

```{r}
#Modelo Elastic Net

set.seed(123)

mod_1_EN <- train(Pobre~.,#Modelo 1 Elastic Net
    data=train_factors,
    metric = "Accuracy",
    method = "glmnet",
    trControl = ctrl,
    tuneGrid=expand.grid(
              alpha = seq(0,1,by=.2),
              lambda =10^seq(10, -2, length = 10)
    )
               
)
```

##2.2 Resultado_EN

```{r}
mod_1_EN
```

##2.2 Modelo F1

```{r}
p_load(Metrics)
fiveStats <- function(...)  c(prSummary(...))  


ctrl<- trainControl(method = "cv",
                    number = 5,
                    classProbs = TRUE,
                    summaryFunction = fiveStats,
                    savePredictions = TRUE)
```

```{r}

set.seed(123)
mod_1_F <- train(Pobre~.,
    data=train_factors,
    metric = "F",
    method = "glmnet",
    trControl = ctrl,
    family="binomial",
    tuneGrid=expand.grid(
              alpha = seq(0,1,by=.5),
              lambda =10^seq(-1, -3, length = 10)
    )

)
```

##2.4 Resultado_F1

```{r}
mod_1_F
```

#3. Entrenamiento Modelo Logit

##3.1 Estimadores logit

```{r}
#Calculo de los estimadores Logit
mod_1_logit<- glm(Pobre~., 
                 data = train_factors, 
                 family = "binomial")

```

##3.2 Resultados Estimadores Logit

```{r}
summary(mod_1_logit,type="text")
```

##3.3 Probabilidad Logit

```{r}
#Calculo de probabilidades
prob_logit<- train_factors %>% 
  mutate(prob_hat=predict(mod_1_logit,
                          newdata = train_factors, 
                          type = "response"))


```

## 3.4 Resultado Probabilidad Logit

```{r}
head(prob_logit %>% 
       select(Pobre,prob_hat))
```

## 3.5 Clasificador Logit

```{r}

rule <- 0.4 # Bayes Rule

prob_logit<- prob_logit %>% 
  mutate(pred_pobre=ifelse(prob_hat>rule,1,0))    ## prediccion de pobre (0) No pobre y (1) Pobre

head(prob_logit %>%
       select(Pobre,prob_hat,pred_pobre))

```

##3.6.1 Matriz de confusion

```{r}
# Convertir la variable Pred_pobre a factor con etiquetas descriptivas
prob_logit$pred_pobre_factor <- factor(prob_logit$pred_pobre,
                                      levels = c(0, 1),
                                      labels = c("No Pobre", "Pobre"))

#Creacion de una matriz de confuncion
#           Predicho
# Real       0    1
#       0   [TN] [FP]
#       1   [FN] [TP]

#Matriz de confusión
A <- with(prob_logit,table(Pobre,pred_pobre_factor))

# Mostrar matriz de confusión
print("Matriz de confusión:")
print(A)

# Explicacion de valores matriz de confusion
TN_train <- A[1]  # Verdaderos Negativos
FP_train <- A[2]  # Falsos Positivos
FN_train <- A[3]  # Falsos Negativos
TP_train <- A[4]  # Verdaderos Positivos

# Crear tabla de conteos
counts_table <- data.frame(
  Categoría = c("Verdaderos Negativos (TN)", "Falsos Positivos (FP)", 
                "Falsos Negativos (FN)", "Verdaderos Positivos (TP)"),
  Conteo = c(TN_train, FP_train, FN_train, TP_train)
)

print(counts_table)


```

##3.6.2 Metricas Modelo Logit

```{r}
#Métricas derivadas:
# Exactitud (Accuracy): (TP + TN) / (TP + TN + FP + FN)
# Proporción de predicciones correctas.
# Precisión (Precision): TP / (TP + FP)
# De todos los casos predichos como "Pobres", ¿cuántos realmente lo son?
# Sensibilidad/Recall: TP / (TP + FN)
# De todos los casos realmente "Pobres", ¿cuántos identificamos correctamente?
# Especificidad: TN / (TN + FP)
# De todos los casos realmente "No pobres", ¿cuántos identificamos correctamente?
# F1-Score: 2 * (Precisión * Recall) / (Precisión + Recall)
# Media armónica de precisión y recall.

# Accuracy
accuracy_train <- (TN_train+ TP_train) / (TN_train + FP_train + FN_train + TP_train)
# Precisión
precision_train <- TP_train / (TP_train + FP_train)
# Recall (Sensibilidad)
recall_train <- TP_train / (TP_train + FN_train)
# Especificidad
specificity_train <- TN_train / (TN_train + FP_train)
# F1 Score
f1_score_train <- 2 * (precision_train * recall_train) / (precision_train + recall_train)
# Error Rate (Tasa de error)
error_rate_train <- 1 - accuracy_train


# Crear tabla de métricas
metrics_table_mod_1_log <- data.frame(
  metrica_train = c("Accuracy (Exactitud)", "Precision (Precisión)", "Recall (Sensibilidad)", 
              "Specificity (Especificidad)", "F1 Score", "Error Rate (Tasa de error)"),
  Valor = c(accuracy_train, precision_train, recall_train, specificity_train, f1_score_train, error_rate_train),
  Descripción = c(
    "Proporción total de predicciones correctas",
    "De los predichos como pobres, cuántos realmente lo son",
    "De los realmente pobres, cuántos fueron identificados correctamente",
    "De los realmente no pobres, cuántos fueron identificados correctamente",
    "Media armónica entre precisión y recall",
    "Proporción de predicciones incorrectas"
  )
)

# Mostrar tabla
print(metrics_table_mod_1_log)

```

##3.7 Entrenamiento Fuera de muestra Modelo_Logit

```{r}
ctrl<- trainControl(method = "cv",
                    number = 5,
                    classProbs = TRUE,
                    savePredictions = TRUE,
                    verbose=T
                    )
```

##3.8 Entrenamiento modelo 2

```{r}
set.seed(123)
mod_2_logit <- train(Pobre~. ,
                     data = train_factors, 
                     method = "glm",
                     family = "binomial",
                     trControl = ctrl,
                     metric = "Accuracy"
                     )

# Ver resultados
print(mod_2_logit)
summary(mod_2_logit)

# Ver predicciones por cada fold
head(mod_2_logit$pred)

```

##3.9 Matriz de confusion modelo 2

```{r}
#Matriz de confusion del modelo de entrenamiento
B <- confusionMatrix(mod_2_logit)

B <- B$table

# Explicacion de valores matriz de confusion
TN_train_cv <- B[1,1]  # Verdaderos Negativos
FP_train_cv <- B[2,1]  # Falsos Positivos
FN_train_cv <- B[1,2]  # Falsos Negativos
TP_train_cv <- B[2,2]  # Verdaderos Positivos

# Calcular métricas
accuracy_train_cv <- (TN_train_cv + TP_train_cv) / (TN_train_cv + FP_train_cv + FN_train_cv + TP_train_cv)
precision_train_cv <- TP_train_cv / (TP_train_cv + FP_train_cv)
recall_train_cv <- TP_train_cv / (TP_train_cv + FN_train_cv)
specificity_train_cv <- TN_train_cv / (TN_train_cv + FP_train_cv)
f1_score_train_cv <- 2 * (precision_train_cv * recall_train_cv) / (precision_train_cv + recall_train_cv)
error_rate_train_cv <- 1 - accuracy_train_cv

# Crear un data frame con los resultados
metrics_table_mod_2_log <- data.frame(
  metrica_train_cv = c("Accuracy (Exactitud)", "Precision (Precisión)", "Recall (Sensibilidad)", 
              "Specificity (Especificidad)", "F1 Score", "Error Rate (Tasa de error)"),
  Valor = c(accuracy_train_cv, precision_train_cv, recall_train_cv, specificity_train_cv, f1_score_train_cv, error_rate_train_cv)
)

print(metrics_table_mod_2_log)
```

##3.10 Explorar la importancia de las variables

```{r}
# Importancia de variables
importancia <- varImp(mod_2_logit, scale = TRUE)
print(importancia)
plot(importancia, top = 20, main = "Las variables más importantes")
```

##3.11 Predición con el Test Set/Clasificacion

```{r}
#Prediccion el Test Set
predictTest_logit <- test_factors %>% 
  mutate(
    prob_pobre = predict(mod_2_logit, 
                         newdata = test_factors, 
                         type = "prob")[,"Yes"],# Probabilidad de ser "Pobre" ("Yes")
    pred_pobre_cat = predict(mod_2_logit, 
                             newdata = test_factors, 
                             type = "raw"), # Predicción categórica (Yes/No)
    pred_pobre = ifelse(pred_pobre_cat == "Yes", 1, 0)# Predicción numérica (1/0)
  )

# Resumen
summary(predictTest_logit$prob_pobre)
table(predictTest_logit$pred_pobre_cat)
table(predictTest_logit$pred_pobre)

# Guardar los resultados
resultados_prediccion<- predictTest_logit %>%
  select(id, pred_pobre)

# Ver las primeras filas de los resultados
head(resultados_prediccion)

```

##3.12 Gráficos de la predicción

```{r}
# Generación de predicciones
predictTest_logit <- test_factors %>% 
  mutate(
    prob_pobre = predict(mod_2_logit, newdata = test_factors, type = "prob")[,"Yes"],
    pred_pobre_cat = predict(mod_2_logit, newdata = test_factors, type = "raw"),
    pred_pobre = ifelse(pred_pobre_cat == "Yes", 1, 0)
  )

# Distribucion de probabilidades predichas
hist(predictTest_logit$prob_pobre, 
     main = "Distribución de probabilidades", 
     xlab = "Probabilidad de ser clasificado como pobre",
     col = "lightblue",
     border = "white",
     breaks = 20)  # Puedes ajustar el número de rangos

# Proporción de clases predichas
prop_clases <- prop.table(table(predictTest_logit$pred_pobre))
print(prop_clases)

# Visualizar proporción de clases en un gráfico de barras
barplot(prop_clases,
        main = "Proporción de clases predichas",
        xlab = "Clase (0 = No pobre, 1 = Pobre)",
        ylab = "Proporción",
        col = c("lightgreen", "coral"),
        names.arg = c("No pobre", "Pobre"),
        ylim = c(0, 1))

# Agregar etiquetas de porcentaje
text(x = 1:length(prop_clases), 
     y = prop_clases + 0.05,
     labels = paste0(round(prop_clases * 100, 1), "%"),
     cex = 0.8)

# AHORA puedes guardar solo las columnas necesarias para la entrega
resultados_prediccion <- predictTest_logit %>%
  select(id, pred_pobre)

# Ver las primeras filas de los resultados
head(resultados_prediccion)
```

##3.12 Template_Logit

```{r}
write.csv(resultados_prediccion, "/Users/jorgeviafara/Library/CloudStorage/OneDrive-Personal/MAESTRIA EN ECONOMIA/01 MATERIAS MECA/4107 BIG DATA/T2_BDML_personal/01042025sample_equipo4_Logit.csv", row.names = FALSE)
```

#3 Predicciones

##3.1 Predicción_EN

```{r}

predictSample_EN <- test_factors   %>% 
  mutate(pobre_lab = predict(mod_1_EN, 
                             newdata = test_factors, 
                             type = "raw"))%>% 
  select(id,pobre_lab)

head(predictSample_EN)

```

```{r}
predictSample_EN<- predictSample_EN %>% 
                  mutate(pobre=ifelse(pobre_lab=="Yes",1,0)) %>% 
                  select(id,pobre)
head(predictSample_EN) 
```

```{r}
nrow(predictSample_EN)
str(predictSample_EN)
head(predictSample_EN)
```

##3.2 Template_EN

```{r}
write.csv(predictSample_EN, "/Users/jorgeviafara/Library/CloudStorage/OneDrive-Personal/MAESTRIA EN ECONOMIA/01 MATERIAS MECA/4107 BIG DATA/T2_BDML_personal/sample_equipo4_EN.csv", row.names = FALSE)

```

```{r}
str(predictSample_EN)  # Verifica estructura
summary(predictSample_EN)  # Estadísticas básicas
head(predictSample_EN, 10)  # Muestra las primeras 10 filas
```

# 4. Entrenamiento Ramdon Forest

## 4.1 Entrenamiento modelo con randomForest (sin crossvalidation)

```{r}
randomforest <- randomForest::randomForest(Pobre ~ . ,
               data = train_factors, 
               mtry = 4,  # Valor óptimo encontrado en CV
               ntree = 500,  # Número de árboles
               importance = TRUE)  # Para ver la importancia de variables
          
# Ver resultados
print(randomforest)

```

```{r}
# Ver importancia de variables
randomForest::varImpPlot(randomforest)
```

## 4.2 Ajustar la base test_factors

```{r}
# Verificar si 'Pobre' falta en test_factors y agregarlo correctamente
if (!("Pobre" %in% names(test_factors))) {
  test_factors$Pobre <- factor(NA, levels = levels(train_factors$Pobre))
}

# Asegurar que test_factors tenga todas las variables de train_factors
missing_vars <- setdiff(names(train_factors), names(test_factors))
for (var in missing_vars) {
  test_factors[[var]] <- NA  
}

# Reordenar columnas para que coincidan
test_factors <- test_factors[, names(train_factors), drop = FALSE]

# Ajustar niveles de factores
for (col in names(test_factors)) {
  if (is.factor(train_factors[[col]])) {
    test_factors[[col]] <- factor(test_factors[[col]], levels = levels(train_factors[[col]]))
  }
}

# Verificar si Pobre ya no es puro NA
table(test_factors$Pobre, useNA = "always")

```

## 4.3 Predicción con el modelo Random Forest

```{r}

# Predicciones con randomForest
rf_pred_probs <- predict(randomforest, newdata = test_factors, type = "prob")
rf_pred_probs
rf_pred_classes <- predict(randomforest, newdata = test_factors)
table(rf_pred_classes)

```

## 4.4 Predición Random Forest con el Test Set/Clasificacion

```{r}
#Prediccion el Test Set
predictTest_rf <- test_factors %>% 
  mutate(
    prob_pobre_rf= predict(randomforest, 
                         newdata = test_factors, 
                         type = "prob")[,"Yes"],# Probabilidad de ser "Pobre" ("Yes")
    pred_pobre_cat_rf = ifelse(prob_pobre_rf > 0.5, "Yes", "No"), #Cambio del umbral de referencia
    pred_pobre_rf = ifelse(pred_pobre_cat_rf == "Yes", 1, 0)# Predicción numérica (1/0)
  )

# Resumen
summary(predictTest_rf$prob_pobre_rf)
table(predictTest_rf$pred_pobre_cat_rf)
table(predictTest_rf$pred_pobre_rf)

# Guardar los resultados
resultados_prediccion_rf<- predictTest_rf %>%
  select(id, pred_pobre_rf)

# Ver las primeras filas de los resultados
head(resultados_prediccion_rf)
```

## 4.5 Template_RF

```{r}
## Template_RF
write.csv(resultados_prediccion_rf, "C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller2/T2_BDML/Predictions/040425sample_equipo4_rf.csv", row.names = FALSE)
```

## 4.6 Entrenamiento fuera de muestra cross validation con ranger

```{r}
# Fijar semilla
set.seed(123)

fiveStats <- function(...) {
  c(
    caret::twoClassSummary(...),  # ROC, Sensibilidad, Especificidad
    caret::defaultSummary(...)    # Accuracy y Kappa
  )
}

ctrl_rf_cv <- trainControl(
  method = "cv",             # cross validation
  number = 5,                
  summaryFunction = fiveStats,
  classProbs = TRUE,         #probabilidades
  verbose = FALSE,
  savePredictions = TRUE
)

# Definimos el grid sobre la que se realizará la busqueda de hiperparámetros
mtry_grid <- expand.grid(
  mtry = 4,
  splitrule = "gini",
  min.node.size = 1
)

```

## 4.7 Entrenamiento del modelo para buscar la mejor combinación de parámetros, se usa ranger con cross validation

```{r}
# Eliminar municipio 
train_factors <- train_factors %>% 
  select(-Dominio, -id)


cv_rf <- train(
  Pobre ~ .,
  data = train_factors,
  method = "ranger",
  metric = "ROC",
  tuneGrid = mtry_grid,
  trControl = ctrl_rf_cv,
  num.trees = 500,
  importance = "impurity"  # Para calcular importancia de variables
)

print(cv_rf)

```

## 4.8 Predicciones con ranger y randomForest

```{r}
#Prediccion el Test Set
predictTest_rf_cv <- test_factors %>% 
  mutate(
    prob_pobre_rf_cv = predict(cv_rf, 
                         newdata = test_factors, 
                         type = "prob")[,"Yes"],# Probabilidad de ser "Pobre" ("Yes")
    
    pred_pobre_cat_rf_cv = ifelse(prob_pobre_rf_cv > 0.5, "Yes", "No"), #Cambio del umbral de referencia
    pred_pobre_rf_cv = ifelse(pred_pobre_cat_rf_cv == "Yes", 1, 0)# Predicción numérica (1/0)
  )

# Resumen
summary(predictTest_rf_cv$prob_pobre_rf_cv)
table(predictTest_rf_cv$pred_pobre_cat_rf_cv)
table(predictTest_rf_cv$pred_pobre_rf_cv)

# Guardar los resultados
resultados_prediccion_rf_cv <- predictTest_rf_cv %>%
   select(id, pred_pobre_rf_cv)

# Ver las primeras filas de los resultados
head(resultados_prediccion_rf_cv)

```

```{r}
# Ver importancia de variables en ranger
plot(varImp(cv_rf), top = 10)

```

## 4.5 Template_RF_CV

```{r}
## Template_RF
write.csv(resultados_prediccion_rf_cv, "C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller2/T2_BDML/Predictions/050425sample_equipo4_rf_cv.csv", row.names = FALSE)
```

```{r}
# Comparar AUC de ambos modelos

# Modelo RandomForest (sin CV)
aucval_rf <- Metrics::auc(
  actual = predictTest_rf$pred_pobre_rf,          
  predicted = predictTest_rf$prob_pobre_rf        
)

# Modelo RandomForest (con CV - ranger)
aucval_rf_cv <- Metrics::auc(
  actual = predictTest_rf_cv$pred_pobre_rf_cv,         
  predicted = predictTest_rf_cv$prob_pobre_rf_cv    
)

# Mostrar resultados
print(paste("AUC RandomForest: ", round(aucval_rf, 4)))
print(paste("AUC Ranger (CV): ", round(aucval_rf_cv, 4)))

```

##5. Entrenamiento Boosting

##5.1. XGBoost

```{r}
p_load(xgboost)

grid_xgboost <- expand.grid(nrounds = c(250,500),
                            max_depth = c(1, 2),
                            eta = c(0.1,  0.01), 
                            gamma = c(0, 1), 
                            min_child_weight = c(10, 25),
                            colsample_bytree = c(0.4, 0.7), 
                            subsample = c(0.7))
grid_xgboost
```

```{r}

ctrl_xgboost <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,                   # Necesario para AUC
  summaryFunction = twoClassSummary,  # Calcula ROC
  verboseIter = FALSE
)

# Entrenar el modelo XGBoost 
set.seed(123)
xgb_model <- train(
  Pobre ~ .,                          # Variable objetivo
  data = train_factors,               # Datos de entrenamiento
  method = "xgbTree",
  trControl = ctrl_xgboost,
  tuneGrid = grid_xgboost,
  metric = "ROC",                     # Se usa ROC como criterio
  verbosity = 0
)

print(xgb_model)

```

```{r}
# Obtener probabilidades
pred_prob_xgboost <- predict(xgb_model, newdata = test_factors, type = "prob")
Pobre_binaria_xgboost <- ifelse(pred_prob_xgboost[, "Yes"] >= 0.5, 1, 0)
resultados_prediccion_xgboost <- data.frame(id = test$id, Pobre = Pobre_binaria_xgboost)

table(resultados_prediccion_xgboost$Pobre)


```

```{r}
## Template_RF
write.csv(resultados_prediccion_xgboost, "C:/Users/njaco/OneDrive/Documentos/Mestría en Economía Aplicada/Semestre 3/Big Data y Machine Learning/Repositorios/T2_BDML/Predictions/sample_equipo4_xgboost.csv", row.names = FALSE)
```

## 5.1. AdaBoost

```{r}
fiveStats <- function(...) {
  c(
    caret::twoClassSummary(...), # Returns ROC, Sensitivity, and Specificity
    caret::defaultSummary(...)  # Returns RMSE and R-squared (for regression) or Accuracy and Kappa (for classification)
  )
}
                                                                        

ctrl<- trainControl(method = "cv",
                     number = 5,
                     summaryFunction = fiveStats,
                     classProbs = TRUE, 
                     verbose=FALSE,
                     savePredictions = T)
```

```{r}
adagrid<-  expand.grid(
              mfinal = c( 50, 100),
              maxdepth = c(1,2),
              coeflearn = c('Breiman'))
```

```{r}
train$Pobre <- as.factor(train$Pobre)
levels(train$Pobre) <- c("No", "Si")

str(train$Pobre)

```

```{r}
train$Dominio <- as.factor(train$Dominio)

```

```{r}
set.seed(123)  # Para reproducibilidad

adaboost_tree <- train(Pobre ~ .,  
  data = train,
  method = "AdaBoost.M1",
  trControl = ctrl,
  metric = "ROC",
  tuneGrid = adagrid
)

print(adaboost_tree)
```

```{r}
set.seed(123)  # Para reproducibilidad

adaboost_tree <- train(Pobre ~ . -Dominio,  # Quitamos Dominio
  data = train, 
  method = "AdaBoost.M1",  
  trControl = ctrl,
  metric = "ROC",
  tuneGrid = adagrid
)

adaboost_tree

```

```{r}
default<- ifelse(test$Default=="Si",1,0)
pred_prob <- predict(adaboost_tree,
                     newdata = test, 
                     type = "prob")   


aucval_AdaBoost <- Metrics::auc(actual = default,predicted = pred_prob[,2])
aucval_AdaBoost
```

# 6. Entrenamiento algoritmo Caret

## 6.1 Entrenamiento del algoritmo CART- Cuando usamos rpart sin fijar un parámetro de complejidad cp el arbol es podado usando por α = 0,01 por defecto

```{r}
# Ver importancia de variables
importancia <- arbol$variable.importance
print(importancia)
```

```{r}
train_factors_model <- train_factors %>% select(-id)



arbol <- rpart(Pobre ~ Nper + nmujeres + ncotizando + maxEducLevel + nt_trab_semanal 
               + H_cotizando + nmayor_edad, 
                       data    = train_factors_model,
                       method = "class" ## define tree for classification
                       )
arbol$control$cp # alpha
```

```{r}
prp(arbol, under = TRUE, branch.lty = 2, yesno = 2, faclen = 0, varlen=15,box.palette = "-RdYlGn")
```

## 6.2 Predicción

```{r}
# variables categóricas del test tengan los mismos niveles y tipos
test_factors_model <- test %>% 
  mutate(Dominio=factor(Dominio),
         pagada=factor(pagada,levels = c(0,1),labels = c("No","Yes")),
         hipoteca=factor(hipoteca,levels = c(0,1),labels = c("No","Yes")),
         arriendo=factor(arriendo,levels = c(0,1),labels = c("No","Yes")),
         usufructo=factor(usufructo,levels = c(0,1),labels = c("No","Yes")),
         sin_titulo=factor(sin_titulo,levels = c(0,1),labels = c("No","Yes")),
         H_Head_Educ_level = factor(H_Head_Educ_level, levels = c(0:6), labels = c("Ns", "Ninguno", "Preescolar", "Primaria", "Secundaria", "Media", "Universitaria")),
         maxEducLevel = factor(maxEducLevel, levels = c(0:6), labels = c("Ns", "Ninguno", "Preescolar", "Primaria", "Secundaria", "Media", "Universitaria"))
  )

pred_prob_cart <- predict(arbol, newdata = test_factors_model, type = "prob")    ## Predecir la probabilidad (en lugar de la clase)
```

```{r}
# Para Kaggle
ids <- test$id

# Convertir probabilidades 
pred_binaria <- ifelse(pred_prob_cart[, "Yes"] > 0.5, 1, 0)


submission <- data.frame(id = ids, Pobre = pred_clase)
```

##3.2 Template_CART

```{r}
write.csv(submission, "C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller2/05-04-25_equipo4_cart.csv", row.names = FALSE)
```
