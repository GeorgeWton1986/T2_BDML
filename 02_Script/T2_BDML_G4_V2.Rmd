---
title: "Taller_2"
author: GARCIA BERNAL, ZAIRA ALEJANDRA RIVERA SANABRIA, LAURA SARIF JACOME VELASCO,
  NICOLAS VIAFARA MORALES, JORGE ELIECER
date: "2025-03-22"
output: html_document
---

```{r}
#Cargar los paquetes de trabajo
require("pacman")
p_load(tidyverse, # tidy-data
       dplyr,
       glmnet, # To implement regularization algorithms. 
       caret, # creating predictive models
       BiocManager,
       Metrics,
       readr,
       utils,
       rpart,
       rpart.plot,
       xgboost)

install.packages("MLmetrics") # To calculate metrics
require(MLmetrics)
```

```{r}
## 1. Carga de datos train hogares

library(httr)

# Definir URL del archivo Excel en GitHub
url_excel <- "https://raw.githubusercontent.com/GeorgeWton1986/T2_BDML/refs/heads/main/03_Stores/train_hogares.csv"

# Descargar el archivo temporalmente
temp_file <- tempfile(fileext = ".csv")
GET(url_excel, write_disk(temp_file, overwrite = TRUE))

# Leer el archivo CSV en un dataframe
train_hogares <- read_csv(temp_file)

## 2. Carga de datos train personas

# URL del archivo ZIP en GitHub
url_zip <- "https://github.com/GeorgeWton1986/T2_BDML/raw/refs/heads/main/03_Stores/train_personas.zip"

# Crear un archivo temporal para almacenar el ZIP
temp_zip <- tempfile(fileext = ".zip")

# Descargar el archivo ZIP desde GitHub
GET(url_zip, write_disk(temp_zip, overwrite = TRUE))
temp_dir <- tempfile()
dir.create(temp_dir)

# Extraer el contenido del ZIP
unzip(temp_zip, exdir = temp_dir)

# Leer el archivo CSV extraído
csv_personas1 <- file.path(temp_dir, "train_personas.csv")
train_personas <- read_csv(csv_personas1)

## 3. Carga de datos test hogares

# Definir URL del archivo Excel en GitHub
url_excel_test <- "https://raw.githubusercontent.com/GeorgeWton1986/T2_BDML/refs/heads/main/03_Stores/test_hogares.csv"

# Descargar el archivo temporalmente
temp_file <- tempfile(fileext = ".csv")
GET(url_excel_test, write_disk(temp_file, overwrite = TRUE))

# Leer el archivo CSV en un dataframe
test_hogares <- read_csv(temp_file)

## 4. Carga de datos test personas

# Definir URL del archivo Excel en GitHub
url_excel_test2 <- "https://raw.githubusercontent.com/GeorgeWton1986/T2_BDML/refs/heads/main/03_Stores/test_personas.csv"

# Descargar el archivo temporalmente
temp_file <- tempfile(fileext = ".csv")
GET(url_excel_test2, write_disk(temp_file, overwrite = TRUE))

# Leer el archivo CSV en un dataframe
test_personas <- read_csv(temp_file)
```

##A.1 Inspección de Base Train Hogares

```{r}
#Nombre de las columnas de la base train_hogares
colnames(train_hogares)

#Seleccion de la columnas id de hogares
train_hogares %>%
  select(id) %>%
  head()

#Cantidad de hogares probres de la base train_hogares
table(train_hogares$Pobre)

#Incluir una columna con la asignacion de 1 si el ingreso per capita hogar es menor a la linea de probreza y 0 en caso contrario
train_hogares <- train_hogares %>% 
  mutate(pobre_hand=ifelse(Ingpcug<Lp,1,0))

#Representación en tabla de los resultado
table(train_hogares$Pobre,train_hogares$pobre_hand)

```

##A.2 Inspeccionar Base Train Personas

```{r}
#Nombre de las columnas de la base train_personas

colnames(train_personas)

#Selección de la columnas id y orden de los mienbros de la base personas
train_personas %>%
  select(id, Orden) %>%
  head()

#Agrupa las personas por hogar y calculo del indicie de personas inactivas
train_personas_1<- train_personas %>%
  group_by(id)%>%
  summarize(h_inactivos=sum(Ina, na.rm = TRUE),
            h_pet=sum(Pet, na.rm = TRUE))%>%
  mutate(h_inactivosp=h_inactivos/h_pet) %>%
  ungroup()
```

#B Test

##B.1 Inspección Base Test Hogares

```{r}
#Nombre de las columnas de la base test_hogares

colnames(test_hogares)

#Selección de la columnas id y número de personas por hogar
test_hogares %>%
  select(id, Npersug) %>%
  head()
```

##B.2 Inspección Base Test Personas

```{r}
#Nombre de las columnas de la base test_personas

colnames(test_personas)
```

#1. Pre procesamiento de Train personas y Train hogares

```{r}
#Pre procesamiento de la base Train_Personas
clear_train_personas <- train_personas %>% 
  mutate(mujer = ifelse(P6020==2,1,0),
  mayor_edad = ifelse(P6040 >= 18,1,0), #Mayores de edad
  H_Head = ifelse(P6050== 1, 1, 0), #Household head
  afi_salud = ifelse (P6090==1,1,0), #Afiliacion de salud
  afi_salud = ifelse (is.na(afi_salud),0,1), #Reemplazo de los NA
  EducLevel = ifelse(P6210==9,0,P6210), #Replace 9 with 0
  EducLevel = ifelse(is.na(EducLevel),0,EducLevel),#Reemplazo de los NA
  act_semana_pasada = ifelse(P6240 == 6,0,P6240),
  act_semana_pasada = ifelse(is.na(act_semana_pasada),0,act_semana_pasada), #Reemplazo de los NA
  t_trab_semanal = ifelse(is.na(P6426),0,1),
  cotizando = ifelse(P6920 == 3, 1, P6920), #Incluir los pensionados
  cotizando = ifelse(is.na(cotizando),0,cotizando),#Reemplazo de los NA
  ocupado = ifelse(is.na(Oc),0,1)) %>%
  select(id, Orden,mujer,mayor_edad,H_Head,afi_salud,EducLevel,act_semana_pasada,t_trab_semanal,cotizando,ocupado)

#Pre procesamiento de la base Test_Personas
clear_test_personas <- test_personas %>% 
  mutate(mujer = ifelse(P6020==2,1,0),
  mayor_edad = ifelse(P6040 >= 18,1,0), #Mayores de edad
  H_Head = ifelse(P6050== 1, 1, 0), #Household head
  afi_salud = ifelse (P6090==1,1,0), #Afiliacion de salud
  afi_salud = ifelse (is.na(afi_salud),0,1), #Reemplazo de los NA
  EducLevel = ifelse(P6210==9,0,P6210), #Replace 9 with 0
  EducLevel = ifelse(is.na(EducLevel),0,EducLevel),#Reemplazo de los NA
  act_semana_pasada = ifelse(P6240 == 6,0,P6240),
  act_semana_pasada = ifelse(is.na(act_semana_pasada),0,act_semana_pasada), #Reemplazo de los NA
  t_trab_semanal = ifelse(is.na(P6426),0,1),
  cotizando = ifelse(P6920 == 3, 1, P6920), #Incluir los pensionados
  cotizando = ifelse(is.na(cotizando),0,cotizando),#Reemplazo de los NA
  ocupado = ifelse(is.na(Oc),0,1)) %>%
  select(id, Orden,mujer,mayor_edad,H_Head,afi_salud,EducLevel,act_semana_pasada,t_trab_semanal,cotizando,ocupado)

colnames(clear_train_personas)

colnames(clear_test_personas)
```

##1.2 Agrupar y unir Train Personas

```{r}
#Agrupar el entrenamiento de la base personas a nivel hogar y unir las bases de datos por medio de id.

summary_train_personas_nivel_hogar <- clear_train_personas %>% 
  group_by(id) %>% 
  summarize(nmujeres = sum(mujer,na.rm=TRUE),
            nmayor_edad = sum(mayor_edad,na.rm=TRUE),
            nafi_salud = sum(afi_salud, na.rm = TRUE),
            maxEducLevel = max(EducLevel,na.rm=TRUE),
            nt_trab_semanal = sum(t_trab_semanal,na.rm = TRUE),
            ncotizando = sum(cotizando,na.rm = TRUE),
            nocupados=sum(ocupado,na.rm=TRUE))

filter_train_personas_hogar<- clear_train_personas %>% 
                  filter(H_Head==1) %>% 
                  select(id,mujer,afi_salud,EducLevel,cotizando,ocupado) %>% 
                  rename(H_Head_mujer=mujer,
                         H_afi_salud = afi_salud,
                         H_Head_Educ_level=EducLevel,
                         H_cotizando = cotizando,
                         H_Head_ocupado=ocupado) %>% 
                    left_join(summary_train_personas_nivel_hogar)

colnames(filter_train_personas_hogar)
```

##1.3 Agrupar y unir Test Personas

```{r}
#Agrupar la prueba de la base personas a nivel hogar y unir las bases de datos por medio de id.


summary_test_personas_nivel_hogar <- clear_test_personas %>% 
  group_by(id) %>% 
  summarize(nmujeres = sum(mujer,na.rm=TRUE),
            nmayor_edad = sum(mayor_edad,na.rm=TRUE),
            nafi_salud = sum(afi_salud, na.rm = TRUE),
            maxEducLevel = max(EducLevel,na.rm=TRUE),
            nt_trab_semanal = sum(t_trab_semanal,na.rm = TRUE),
            ncotizando = sum(cotizando,na.rm = TRUE),
            nocupados=sum(ocupado,na.rm=TRUE))

filter_test_personas_hogar<- clear_test_personas %>% 
                  filter(H_Head==1) %>% 
                  select(id,mujer,afi_salud,EducLevel,cotizando,ocupado) %>% 
                  rename(H_Head_mujer=mujer,
                         H_afi_salud = afi_salud,
                         H_Head_Educ_level=EducLevel,
                         H_cotizando = cotizando,
                         H_Head_ocupado=ocupado) %>% 
                    left_join(summary_test_personas_nivel_hogar, by = "id")

colnames(filter_test_personas_hogar)
```

##1.4 Base de trabajo Train Hogares

```{r}
clear_train_hogares<- train_hogares %>% 
  mutate(pagada= ifelse(P5090==1,1,0),
         hipoteca= ifelse(P5090==2,1,0),
         arriendo= ifelse(P5090==3,1,0),
         usufructo= ifelse(P5090==4,1,0),
         sin_titulo = ifelse(P5090==5,1,0)) %>% 
  select(id, Clase, Nper, Dominio,pagada, hipoteca, arriendo, usufructo, sin_titulo, Lp, Pobre)
```

##1.5 Base de trabajo Test Hogares

```{r}
clear_test_hogares<- test_hogares %>% 
  mutate(pagada= ifelse(P5090==1,1,0),
         hipoteca= ifelse(P5090==2,1,0),
         arriendo= ifelse(P5090==3,1,0),
         usufructo= ifelse(P5090==4,1,0),
         sin_titulo = ifelse(P5090==5,1,0)) %>% 
  select(id, Clase, Nper, Dominio, pagada, hipoteca, arriendo, usufructo, sin_titulo, Lp)
```

##1.6 Consolidar las BD Train y Test Hogares

```{r}
train<- clear_train_hogares %>% 
          left_join(filter_train_personas_hogar)

test<- clear_test_hogares %>% 
          left_join(filter_test_personas_hogar)

```

##1.7 Conversion a factores

```{r}
train_factors<- train %>% 
  mutate(Dominio=factor(Dominio),
         pagada=factor(pagada,levels = c(0,1),labels = c("No","Yes")),
         hipoteca=factor(hipoteca,levels = c(0,1),labels = c("No","Yes")),
         arriendo=factor(arriendo,levels = c(0,1),labels = c("No","Yes")),
         usufructo=factor(usufructo,levels = c(0,1),labels = c("No","Yes")),
         sin_titulo=factor(sin_titulo,levels = c(0,1),labels = c("No","Yes")), #No se tiene documento de propiedad
         Pobre=factor(Pobre,levels = c(0,1),labels = c("No", "Yes")),
         H_Head_Educ_level = factor(H_Head_Educ_level, levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria')),
         maxEducLevel = factor(maxEducLevel,levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria') ))

test_factors<- test %>% 
  mutate(Dominio=factor(Dominio),
         pagada=factor(pagada,levels = c(0,1),labels = c("No","Yes")),
         hipoteca=factor(hipoteca,levels = c(0,1),labels = c("No","Yes")),
         arriendo=factor(arriendo,levels = c(0,1),labels = c("No","Yes")),
         usufructo=factor(usufructo,levels = c(0,1),labels = c("No","Yes")),
         sin_titulo=factor(sin_titulo,levels = c(0,1),labels = c("No","Yes")), #No se tiene documento de propiedad
         H_Head_Educ_level = factor(H_Head_Educ_level, levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria')),
         maxEducLevel = factor(maxEducLevel,levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria') ))

```
##1.8 Revision del Balance de Clases Train

```{r}
# Calcular proporción de clases (No pobre vs Pobre)
tabla_pobreza <- table(train_factors$Pobre)
prop_clases_pobreza <- prop.table(tabla_pobreza)

# Visualizar proporción de clases en un gráfico de barras
barplot(prop_clases_pobreza,
        main = "Proporción de clases de pobreza en datos de entrenamiento",
        xlab = "Condición de pobreza",
        ylab = "Proporción",
        col = c("lightgreen", "coral"),
        names.arg = c("No pobre", "Pobre"),
        ylim = c(0, 1))

# Agregar etiquetas de porcentaje
text(x = 1:length(prop_clases_pobreza), 
     y = prop_clases_pobreza + 0.05,
     labels = paste0(round(prop_clases_pobreza * 100, 1), "%"),
     cex = 0.8)
```

#2. Entrenamiento Modelo Elastic Net
##2.1 Modelo Elastic Net con Caret
```{r}
#Configacion de la validacion Cruzada
ctrl_EN<- trainControl(method = "cv",
                    number = 5,
                    classProbs = TRUE,
                    savePredictions = TRUE,
                    summaryFunction = twoClassSummary, #Es usada para metricas como F1
                    )
```

##2.2 Definir la cuadricula de hiperparametros
```{r}
#Definir la grilla de los hiperparametros alfa y lambda
# El hipeparametro alfa controla Ridge (0) y Lasso (1)
# El hipeparametro lambda controla la intensidad de la regularización

grilla_EN <- expand.grid(
  alpha= c(0.1, 0.3, 0.5, 0.7, 0.9),
  lambda= 10^seq(-4, -1, length = 10) #Logaritmos
)

```

##2.3 Entrenar el modelo Elastic Net
```{r}
#Modelo Elastic Net
#Tiempo para ejecucion 6 min

#Entrenamiento del modelo
set.seed(123)

mod_1_EN <- train(Pobre~., #Modelo 1 Elastic Net
    data=train_factors, #Datos de entrenamiento en factores
    method = "glmnet", #Metodo de cálculo Elastic Net
    trControl = ctrl_EN, #Validacion Cruzada
    tuneGrid = grilla_EN, #Grilla de Hiperparametros
    metric = "ROC", # Metrica F1 es usada para conjunto de datos que estan desbalanceados
    preProcess = c("center","scale","zv") #Preprocesamiento
    )
```

##2.4 Resultado modelo Elastic Net
```{r}
# Resumen del modelo entrenado  Elastic Net
print(mod_1_EN)

# Resumen hiperparámetros 
print(mod_1_EN$bestTune)

# Resultados de validación cruzada
plot(mod_1_EN)


```

##2.5 Matriz de confusion Elatic Net
```{r}
#Umbral de decision de Probreza
umbral <- 0.3

#obtener la probabilidad de los datos de entrenamiento
prob_train <- predict(mod_1_EN, newdata = train_factors, type = "prob")[,"Yes"]

# Obtener predicciones en los datos de entrenamiento
predicciones_train <- ifelse(prob_train > umbral, "Yes", "No")
predicciones_train <- factor(predicciones_train, levels = levels(train_factors$Pobre))

# Matriz de confusión del modelo Elastic Net
B_EN <- confusionMatrix(predicciones_train, train_factors$Pobre)
B_EN <- B_EN$table

# Explicación de valores matriz de confusión
TN_train_EN <- B_EN[1,1]  # Verdaderos Negativos
FP_train_EN <- B_EN[1,2]  # Falsos Positivos
FN_train_EN <- B_EN[2,1]  # Falsos Negativos
TP_train_EN <- B_EN[2,2]  # Verdaderos Positivos

# Crear tabla de conteos
counts_table_EN <- data.frame(
  categoría = c("Verdaderos Negativos (TN)", "Falsos Positivos (FP)", 
                "Falsos Negativos (FN)", "Verdaderos Positivos (TP)"),
  conteo = c(TN_train_EN, FP_train_EN, FN_train_EN, TP_train_EN)
)

print(counts_table_EN)

```

##2.6 Metricas Modelo Elastic Net
```{r}
# Calcular métricas
accuracy_train_EN <- (TN_train_EN + TP_train_EN) / (TN_train_EN + FP_train_EN + FN_train_EN + TP_train_EN)
precision_train_EN <- TP_train_EN / (TP_train_EN + FP_train_EN)
recall_train_EN <- TP_train_EN / (TP_train_EN + FN_train_EN)
specificity_train_EN <- TN_train_EN / (TN_train_EN + FP_train_EN)
f1_score_train_EN <- 2 * (precision_train_EN * recall_train_EN) / (precision_train_EN + recall_train_EN)
error_rate_train_EN <- 1 - accuracy_train_EN

# Crear un data frame con los resultados
metrics_table_mod_1_EN <- data.frame(
  metrica_train_cv = c("Accuracy (Exactitud)", "Precision (Precisión)", "Recall (Sensibilidad)", 
              "Specificity (Especificidad)", "F1 Score", "Error Rate (Tasa de error)"),
  Valor = c(accuracy_train_EN, precision_train_EN, recall_train_EN, specificity_train_EN, f1_score_train_EN, error_rate_train_EN),
    Descripción = c(
    "Proporción total de predicciones correctas",
    "De los predichos como pobres, cuántos realmente lo son",
    "De los realmente pobres, cuántos fueron identificados correctamente",
    "De los realmente no pobres, cuántos fueron identificados correctamente",
    "Media armónica entre precisión y recall",
    "Proporción de predicciones incorrectas"
))

# Imprimir tabla de métricas
print(metrics_table_mod_1_EN)
```

##2.6 Explorar la importancia de las variables
```{r}
# Ver la importancia de las variables
importancia <- varImp(mod_1_EN)
plot(importancia, top = 10)  # Mostrar las 20 variables más importantes
```
##2.6 Prediccion con el Test Set Elastic Net
```{r}
#Prediccion el Test Set
predictTest_EN <- test_factors %>%
  mutate(prob_probre_EN = predict(mod_1_EN,
         newdata = test_factors,
         type = "prob")[,"Yes"],
         pred_probre_cat_EN = ifelse(prob_probre_EN > umbral, "Yes", "No"), #Cambio del umbral de referencia
         pred_probre_EN = ifelse(pred_probre_cat_EN == "Yes", 1, 0)# Predicción numérica (1/0)
         )

# Resumen verificación
summary(predictTest_EN$prob_probre_EN)
table(predictTest_EN$pred_probre_cat_EN)
table(predictTest_EN$pred_probre_EN)

# Guardar los resultados
resultados_prediccion_EN<- predictTest_EN %>%
  select(id, pred_probre_EN)

# Ver las primeras filas de los resultados
head(resultados_prediccion_EN)
```
##2.7 Gráficos de la predicción
```{r}
# Distribucion de probabilidades predichas
hist(predictTest_EN$prob_probre_EN, 
     main = "Distribución de probabilidades", 
     xlab = "Probabilidad de ser clasificado como pobre",
     col = "lightblue",
     border = "white",
     breaks = 20)  # Puedes ajustar el número de rangos

# Proporción de clases predichas
prop_clases_EN <- prop.table(table(predictTest_EN$pred_probre_EN))
print(prop_clases_EN)

# Visualizar proporción de clases en un gráfico de barras
barplot(prop_clases_EN,
        main = "Proporción de clases predichas",
        xlab = "Clase (0 = No pobre, 1 = Pobre)",
        ylab = "Proporción",
        col = c("lightgreen", "coral"),
        names.arg = c("No pobre", "Pobre"),
        ylim = c(0, 1))

# Agregar etiquetas de porcentaje
text(x = 1:length(prop_clases_EN), 
     y = prop_clases_EN + 0.05,
     labels = paste0(round(prop_clases_EN * 100, 1), "%"),
     cex = 0.8)


```

##2.8 Template Elastic Net
```{r}
write.csv(resultados_prediccion_EN, "/Users/jorgeviafara/Library/CloudStorage/OneDrive-Personal/MAESTRIA EN ECONOMIA/01 MATERIAS MECA/4107 BIG DATA/T2_BDML_personal/03042025_sample_equipo4_EN.csv", row.names = FALSE)
```

#3. Entrenamiento Modelo Logit

##3.1 Estimadores logit

```{r}
#Calculo de los estimadores Logit
mod_1_logit<- glm(Pobre~., 
                 data = train_factors, 
                 family = "binomial")

```

##3.2 Resultados Estimadores Logit

```{r}
summary(mod_1_logit,type="text")
```

##3.3 Probabilidad Logit

```{r}
#Calculo de probabilidades
prob_logit<- train_factors %>% 
  mutate(prob_hat=predict(mod_1_logit,
                          newdata = train_factors, 
                          type = "response"))


```

## 3.4 Resultado Probabilidad Logit

```{r}
head(prob_logit %>% 
       select(Pobre,prob_hat))
```

## 3.5 Clasificador Logit

```{r}

rule <- 0.4 # Bayes Rule

prob_logit<- prob_logit %>% 
  mutate(pred_pobre=ifelse(prob_hat>rule,1,0))    ## prediccion de pobre (0) No pobre y (1) Pobre

head(prob_logit %>%
       select(Pobre,prob_hat,pred_pobre))

```

##3.6.1 Matriz de confusion

```{r}
# Convertir la variable Pred_pobre a factor con etiquetas descriptivas
prob_logit$pred_pobre_factor <- factor(prob_logit$pred_pobre,
                                      levels = c(0, 1),
                                      labels = c("No Pobre", "Pobre"))

#Creacion de una matriz de confuncion
#           Predicho
# Real       0    1
#       0   [TN] [FP]
#       1   [FN] [TP]

#Matriz de confusión
A <- with(prob_logit,table(Pobre,pred_pobre_factor))

# Mostrar matriz de confusión
print("Matriz de confusión:")
print(A)

# Explicacion de valores matriz de confusion
TN_train <- A[1]  # Verdaderos Negativos
FP_train <- A[2]  # Falsos Positivos
FN_train <- A[3]  # Falsos Negativos
TP_train <- A[4]  # Verdaderos Positivos

# Crear tabla de conteos
counts_table <- data.frame(
  Categoría = c("Verdaderos Negativos (TN)", "Falsos Positivos (FP)", 
                "Falsos Negativos (FN)", "Verdaderos Positivos (TP)"),
  Conteo = c(TN_train, FP_train, FN_train, TP_train)
)

print(counts_table)


```

##3.6.2 Metricas Modelo Logit

```{r}
#Métricas derivadas:
# Exactitud (Accuracy): (TP + TN) / (TP + TN + FP + FN)
# Proporción de predicciones correctas.
# Precisión (Precision): TP / (TP + FP)
# De todos los casos predichos como "Pobres", ¿cuántos realmente lo son?
# Sensibilidad/Recall: TP / (TP + FN)
# De todos los casos realmente "Pobres", ¿cuántos identificamos correctamente?
# Especificidad: TN / (TN + FP)
# De todos los casos realmente "No pobres", ¿cuántos identificamos correctamente?
# F1-Score: 2 * (Precisión * Recall) / (Precisión + Recall)
# Media armónica de precisión y recall.

# Accuracy
accuracy_train <- (TN_train+ TP_train) / (TN_train + FP_train + FN_train + TP_train)
# Precisión
precision_train <- TP_train / (TP_train + FP_train)
# Recall (Sensibilidad)
recall_train <- TP_train / (TP_train + FN_train)
# Especificidad
specificity_train <- TN_train / (TN_train + FP_train)
# F1 Score
f1_score_train <- 2 * (precision_train * recall_train) / (precision_train + recall_train)
# Error Rate (Tasa de error)
error_rate_train <- 1 - accuracy_train


# Crear tabla de métricas
metrics_table_mod_1_log <- data.frame(
  metrica_train = c("Accuracy (Exactitud)", "Precision (Precisión)", "Recall (Sensibilidad)", 
              "Specificity (Especificidad)", "F1 Score", "Error Rate (Tasa de error)"),
  Valor = c(accuracy_train, precision_train, recall_train, specificity_train, f1_score_train, error_rate_train),
  Descripción = c(
    "Proporción total de predicciones correctas",
    "De los predichos como pobres, cuántos realmente lo son",
    "De los realmente pobres, cuántos fueron identificados correctamente",
    "De los realmente no pobres, cuántos fueron identificados correctamente",
    "Media armónica entre precisión y recall",
    "Proporción de predicciones incorrectas"
  )
)

# Mostrar tabla
print(metrics_table_mod_1_log)

```

##3.7 Entrenamiento Fuera de muestra Modelo_Logit

```{r}
ctrl<- trainControl(method = "cv",
                    number = 5,
                    classProbs = TRUE,
                    savePredictions = TRUE,
                    verbose=T
                    )
```

##3.8 Entrenamiento modelo 2

```{r}
set.seed(123)
mod_2_logit <- train(Pobre~. ,
                     data = train_factors, 
                     method = "glm",
                     family = "binomial",
                     trControl = ctrl,
                     metric = "Accuracy"
                     )

# Ver resultados
print(mod_2_logit)
summary(mod_2_logit)

# Ver predicciones por cada fold
head(mod_2_logit$pred)

```

##3.9 Matriz de confusion modelo 2

```{r}
#Matriz de confusion del modelo de entrenamiento
B <- confusionMatrix(mod_2_logit)

B <- B$table

# Explicacion de valores matriz de confusion
TN_train_cv <- B[1,1]  # Verdaderos Negativos
FP_train_cv <- B[2,1]  # Falsos Positivos
FN_train_cv <- B[1,2]  # Falsos Negativos
TP_train_cv <- B[2,2]  # Verdaderos Positivos

# Calcular métricas
accuracy_train_cv <- (TN_train_cv + TP_train_cv) / (TN_train_cv + FP_train_cv + FN_train_cv + TP_train_cv)
precision_train_cv <- TP_train_cv / (TP_train_cv + FP_train_cv)
recall_train_cv <- TP_train_cv / (TP_train_cv + FN_train_cv)
specificity_train_cv <- TN_train_cv / (TN_train_cv + FP_train_cv)
f1_score_train_cv <- 2 * (precision_train_cv * recall_train_cv) / (precision_train_cv + recall_train_cv)
error_rate_train_cv <- 1 - accuracy_train_cv

# Crear un data frame con los resultados
metrics_table_mod_2_log <- data.frame(
  metrica_train_cv = c("Accuracy (Exactitud)", "Precision (Precisión)", "Recall (Sensibilidad)", 
              "Specificity (Especificidad)", "F1 Score", "Error Rate (Tasa de error)"),
  Valor = c(accuracy_train_cv, precision_train_cv, recall_train_cv, specificity_train_cv, f1_score_train_cv, error_rate_train_cv)
)

print(metrics_table_mod_2_log)
```

##3.10 Explorar la importancia de las variables

```{r}
# Importancia de variables
importancia <- varImp(mod_2_logit, scale = TRUE)
print(importancia)
plot(importancia, top = 20, main = "Las variables más importantes")
```

##3.11 Predición con el Test Set/Clasificacion

```{r}
#Prediccion el Test Set
predictTest_logit <- test_factors %>% 
  mutate(
    prob_pobre = predict(mod_2_logit, 
                         newdata = test_factors, 
                         type = "prob")[,"Yes"],# Probabilidad de ser "Pobre" ("Yes")
    pred_pobre_cat = predict(mod_2_logit, 
                             newdata = test_factors, 
                             type = "raw"), # Predicción categórica (Yes/No)
    pred_pobre = ifelse(pred_pobre_cat == "Yes", 1, 0)# Predicción numérica (1/0)
  )

# Resumen
summary(predictTest_logit$prob_pobre)
table(predictTest_logit$pred_pobre_cat)
table(predictTest_logit$pred_pobre)

# Guardar los resultados
resultados_prediccion<- predictTest_logit %>%
  select(id, pred_pobre)

# Ver las primeras filas de los resultados
head(resultados_prediccion)

```

##3.12 Gráficos de la predicción

```{r}
# Generación de predicciones
predictTest_logit <- test_factors %>% 
  mutate(
    prob_pobre = predict(mod_2_logit, newdata = test_factors, type = "prob")[,"Yes"],
    pred_pobre_cat = predict(mod_2_logit, newdata = test_factors, type = "raw"),
    pred_pobre = ifelse(pred_pobre_cat == "Yes", 1, 0)
  )

# Distribucion de probabilidades predichas
hist(predictTest_logit$prob_pobre, 
     main = "Distribución de probabilidades", 
     xlab = "Probabilidad de ser clasificado como pobre",
     col = "lightblue",
     border = "white",
     breaks = 20)  # Puedes ajustar el número de rangos

# Proporción de clases predichas
prop_clases <- prop.table(table(predictTest_logit$pred_pobre))
print(prop_clases)

# Visualizar proporción de clases en un gráfico de barras
barplot(prop_clases,
        main = "Proporción de clases predichas",
        xlab = "Clase (0 = No pobre, 1 = Pobre)",
        ylab = "Proporción",
        col = c("lightgreen", "coral"),
        names.arg = c("No pobre", "Pobre"),
        ylim = c(0, 1))

# Agregar etiquetas de porcentaje
text(x = 1:length(prop_clases), 
     y = prop_clases + 0.05,
     labels = paste0(round(prop_clases * 100, 1), "%"),
     cex = 0.8)

# AHORA puedes guardar solo las columnas necesarias para la entrega
resultados_prediccion <- predictTest_logit %>%
  select(id, pred_pobre)

# Ver las primeras filas de los resultados
head(resultados_prediccion)
```

##3.12 Template_Logit

```{r}
write.csv(resultados_prediccion, "/Users/jorgeviafara/Library/CloudStorage/OneDrive-Personal/MAESTRIA EN ECONOMIA/01 MATERIAS MECA/4107 BIG DATA/T2_BDML_personal/01042025sample_equipo4_Logit.csv", row.names = FALSE)
```

#3 Predicciones

##3.1 Predicción_EN

```{r}

predictSample_EN <- test_factors   %>% 
  mutate(pobre_lab = predict(mod_1_EN, 
                             newdata = test_factors, 
                             type = "raw"))%>% 
  select(id,pobre_lab)

head(predictSample_EN)

```

```{r}
predictSample_EN<- predictSample_EN %>% 
                  mutate(pobre=ifelse(pobre_lab=="Yes",1,0)) %>% 
                  select(id,pobre)
head(predictSample_EN) 
```

```{r}
nrow(predictSample_EN)
str(predictSample_EN)
head(predictSample_EN)
```

##3.2 Template_EN

```{r}
write.csv(predictSample_EN, "/Users/jorgeviafara/Library/CloudStorage/OneDrive-Personal/MAESTRIA EN ECONOMIA/01 MATERIAS MECA/4107 BIG DATA/T2_BDML_personal/sample_equipo4_EN.csv", row.names = FALSE)

```

```{r}
str(predictSample_EN)  # Verifica estructura
summary(predictSample_EN)  # Estadísticas básicas
head(predictSample_EN, 10)  # Muestra las primeras 10 filas
```

# 4. Entrenamiento Ramdon Forest

## 4.1 Entrenamiento modelo con randomForest (sin crossvalidation)

```{r}
randomforest <- randomForest::randomForest(Pobre ~ . ,
               data = train_factors, 
               mtry = 4,  # Valor óptimo encontrado en CV
               ntree = 500,  # Número de árboles
               importance = TRUE)  # Para ver la importancia de variables
          
# Ver resultados
print(randomforest)

```

```{r}
# Ver importancia de variables
randomForest::varImpPlot(randomforest)
```

## 4.2 Ajustar la base test_factors

```{r}
# Verificar si 'Pobre' falta en test_factors y agregarlo correctamente
if (!("Pobre" %in% names(test_factors))) {
  test_factors$Pobre <- factor(NA, levels = levels(train_factors$Pobre))
}

# Asegurar que test_factors tenga todas las variables de train_factors
missing_vars <- setdiff(names(train_factors), names(test_factors))
for (var in missing_vars) {
  test_factors[[var]] <- NA  
}

# Reordenar columnas para que coincidan
test_factors <- test_factors[, names(train_factors), drop = FALSE]

# Ajustar niveles de factores
for (col in names(test_factors)) {
  if (is.factor(train_factors[[col]])) {
    test_factors[[col]] <- factor(test_factors[[col]], levels = levels(train_factors[[col]]))
  }
}

# Verificar si Pobre ya no es puro NA
table(test_factors$Pobre, useNA = "always")

```

## 4.3 Predicción con el modelo Random Forest

```{r}

# Predicciones con randomForest
rf_pred_probs <- predict(randomforest, newdata = test_factors, type = "prob")
rf_pred_probs
rf_pred_classes <- predict(randomforest, newdata = test_factors)
table(rf_pred_classes)

```

## 4.4 Predición Random Forest con el Test Set/Clasificacion

```{r}
#Prediccion el Test Set
predictTest_rf <- test_factors %>% 
  mutate(
    prob_pobre_rf= predict(randomforest, 
                         newdata = test_factors, 
                         type = "prob")[,"Yes"],# Probabilidad de ser "Pobre" ("Yes")
    pred_pobre_cat_rf = ifelse(prob_pobre_rf > 0.5, "Yes", "No"), #Cambio del umbral de referencia
    pred_pobre_rf = ifelse(pred_pobre_cat_rf == "Yes", 1, 0)# Predicción numérica (1/0)
  )

# Resumen
summary(predictTest_rf$prob_pobre_rf)
table(predictTest_rf$pred_pobre_cat_rf)
table(predictTest_rf$pred_pobre_rf)

# Guardar los resultados
resultados_prediccion_rf<- predictTest_rf %>%
  select(id, pred_pobre_rf)

# Ver las primeras filas de los resultados
head(resultados_prediccion_rf)
```

## 4.5 Template_RF

```{r}
## Template_RF
write.csv(resultados_prediccion_rf, "C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller2/T2_BDML/Predictions/040425sample_equipo4_rf.csv", row.names = FALSE)
```

## 4.6 Entrenamiento fuera de muestra cross validation con ranger

```{r}
# Fijar semilla
set.seed(123)

fiveStats <- function(...) {
  c(
    caret::twoClassSummary(...),  # ROC, Sensibilidad, Especificidad
    caret::defaultSummary(...)    # Accuracy y Kappa
  )
}

ctrl_rf_cv <- trainControl(
  method = "cv",             # cross validation
  number = 5,                
  summaryFunction = fiveStats,
  classProbs = TRUE,         #probabilidades
  verbose = FALSE,
  savePredictions = TRUE
)

# Definimos el grid sobre la que se realizará la busqueda de hiperparámetros
mtry_grid <- expand.grid(
  mtry = 4,
  splitrule = "gini",
  min.node.size = 1
)

```

## 4.7 Entrenamiento del modelo para buscar la mejor combinación de parámetros, se usa ranger con cross validation

```{r}
# Eliminar municipio 
train_factors <- train_factors %>% 
  select(-Dominio, -id)


cv_rf <- train(
  Pobre ~ .,
  data = train_factors,
  method = "ranger",
  metric = "ROC",
  tuneGrid = mtry_grid,
  trControl = ctrl_rf_cv,
  num.trees = 500,
  importance = "impurity"  # Para calcular importancia de variables
)

print(cv_rf)

```

## 4.8 Predicciones con ranger y randomForest

```{r}
#Prediccion el Test Set
predictTest_rf_cv <- test_factors %>% 
  mutate(
    prob_pobre_rf_cv = predict(cv_rf, 
                         newdata = test_factors, 
                         type = "prob")[,"Yes"],# Probabilidad de ser "Pobre" ("Yes")
    
    pred_pobre_cat_rf_cv = ifelse(prob_pobre_rf_cv > 0.5, "Yes", "No"), #Cambio del umbral de referencia
    pred_pobre_rf_cv = ifelse(pred_pobre_cat_rf_cv == "Yes", 1, 0)# Predicción numérica (1/0)
  )

# Resumen
summary(predictTest_rf_cv$prob_pobre_rf_cv)
table(predictTest_rf_cv$pred_pobre_cat_rf_cv)
table(predictTest_rf_cv$pred_pobre_rf_cv)

# Guardar los resultados
resultados_prediccion_rf_cv <- predictTest_rf_cv %>%
   select(id, pred_pobre_rf_cv)

# Ver las primeras filas de los resultados
head(resultados_prediccion_rf_cv)

```

```{r}
# Ver importancia de variables en ranger
plot(varImp(cv_rf), top = 10)

```

## 4.5 Template_RF_CV

```{r}
## Template_RF
write.csv(resultados_prediccion_rf_cv, "C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller2/T2_BDML/Predictions/050425sample_equipo4_rf_cv.csv", row.names = FALSE)
```

```{r}
# Comparar AUC de ambos modelos

# Modelo RandomForest (sin CV)
aucval_rf <- Metrics::auc(
  actual = predictTest_rf$pred_pobre_rf,          
  predicted = predictTest_rf$prob_pobre_rf        
)

# Modelo RandomForest (con CV - ranger)
aucval_rf_cv <- Metrics::auc(
  actual = predictTest_rf_cv$pred_pobre_rf_cv,         
  predicted = predictTest_rf_cv$prob_pobre_rf_cv    
)

# Mostrar resultados
print(paste("AUC RandomForest: ", round(aucval_rf, 4)))
print(paste("AUC Ranger (CV): ", round(aucval_rf_cv, 4)))

```

##5. Entrenamiento Boosting

##5.1. XGBoost

```{r}
p_load(xgboost)

grid_xgboost <- expand.grid(nrounds = c(250,500),
                            max_depth = c(1, 2),
                            eta = c(0.1,  0.01), 
                            gamma = c(0, 1), 
                            min_child_weight = c(10, 25),
                            colsample_bytree = c(0.4, 0.7), 
                            subsample = c(0.7))
grid_xgboost
```

```{r}

# Calcular proporción de clases para asignar peso
weight_ratio <- sum(train_factors$Pobre == "No") / sum(train_factors$Pobre == "Yes")

# Crear vector de pesos
weights <- ifelse(train_factors$Pobre == "Yes", weight_ratio, 1)

# Control de entrenamiento con ROC
ctrl <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,                   # Necesario para AUC
  summaryFunction = twoClassSummary,  # Calcula ROC
  verboseIter = FALSE
)

# Entrenar el modelo XGBoost con fórmula directa
set.seed(123)
xgb_model <- train(
  Pobre ~ .,                          # Variable objetivo
  data = train_factors,               # Datos de entrenamiento
  method = "xgbTree",
  trControl = ctrl,
  tuneGrid = grid_xgboost,
  metric = "ROC",     
  weights = weights,                  # <--- este es el cambio importante
  verbosity = 0
)

print(xgb_model)

```

```{r}
# Obtener probabilidades
pred_prob_xgboost <- predict(xgb_model, newdata = test_factors, type = "prob")
Pobre_binaria_xgboost <- ifelse(pred_prob_xgboost[, "Yes"] >= 0.5, 1, 0)
resultados_prediccion_xgboost_2 <- data.frame(id = test$id, Pobre = Pobre_binaria_xgboost)

table(resultados_prediccion_xgboost_2$Pobre)


```

```{r}
## Template_RF
write.csv(resultados_prediccion_xgboost_2, "C:/Users/njaco/OneDrive/Documentos/Mestría en Economía Aplicada/Semestre 3/Big Data y Machine Learning/Repositorios/T2_BDML/Predictions/sample_equipo4_xgboost2.csv", row.names = FALSE)
```

#5.2. Gradient Boosting

```{r}
p_load(gbm)


grid_gbm <- expand.grid(
  n.trees = c(100, 200, 300),
  interaction.depth = c(3, 4),
  shrinkage = c(0.1),
  n.minobsinnode = c(5, 10)
)
```

```{r}
# Definir control de entrenamiento específico para gbm
ctrl_gbm <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummary
)

set.seed(123) # important set seed. 
gbm_tree <- train(Pobre ~ .,
  data = train_factors, 
  method = "gbm", 
  trControl = ctrl_gbm,
  tuneGrid=grid_gbm,
  metric = "ROC",
  verbose = FALSE
)            
gbm_tree
```

```{r}
pred_prob_gbm <- predict(gbm_tree, newdata = test_factors, type = "prob")
pred_clase_gbm <- ifelse(pred_prob_gbm[,"Yes"] > 0.5, 1, 0)
predicciones_kaggle_gbm <- data.frame(id = test$id, Pobre = pred_clase_gbm)
table(predicciones_kaggle_gbm$Pobre)
```

```{r}
setwd("C:/Users/njaco/OneDrive/Documentos/Mestría en Economía Aplicada/Semestre 3/Big Data y Machine Learning")
# Exportar a CSV sin row.names
write.csv(predicciones_kaggle_gbm, "kaggle_submission_gbm.csv", row.names = FALSE)
```

# 6. Entrenamiento algoritmo Caret

## 6.1 Entrenamiento del algoritmo CART- Cuando usamos rpart sin fijar un parámetro de complejidad cp el arbol es podado usando por α = 0,01 por defecto

```{r}
# Ver importancia de variables
importancia <- arbol$variable.importance
print(importancia)
```

```{r}
train_factors_model <- train_factors %>% select(-id)



arbol <- rpart(Pobre ~ Nper + nmujeres + ncotizando + maxEducLevel + nt_trab_semanal 
               + H_cotizando + nmayor_edad, 
                       data    = train_factors_model,
                       method = "class" ## define tree for classification
                       )
arbol$control$cp # alpha
```

```{r}
prp(arbol, under = TRUE, branch.lty = 2, yesno = 2, faclen = 0, varlen=15,box.palette = "-RdYlGn")
```

## 6.2 Predicción

```{r}
# variables categóricas del test tengan los mismos niveles y tipos
test_factors_model <- test %>% 
  mutate(Dominio=factor(Dominio),
         pagada=factor(pagada,levels = c(0,1),labels = c("No","Yes")),
         hipoteca=factor(hipoteca,levels = c(0,1),labels = c("No","Yes")),
         arriendo=factor(arriendo,levels = c(0,1),labels = c("No","Yes")),
         usufructo=factor(usufructo,levels = c(0,1),labels = c("No","Yes")),
         sin_titulo=factor(sin_titulo,levels = c(0,1),labels = c("No","Yes")),
         H_Head_Educ_level = factor(H_Head_Educ_level, levels = c(0:6), labels = c("Ns", "Ninguno", "Preescolar", "Primaria", "Secundaria", "Media", "Universitaria")),
         maxEducLevel = factor(maxEducLevel, levels = c(0:6), labels = c("Ns", "Ninguno", "Preescolar", "Primaria", "Secundaria", "Media", "Universitaria"))
  )

pred_prob_cart <- predict(arbol, newdata = test_factors_model, type = "prob")    ## Predecir la probabilidad (en lugar de la clase)
```

```{r}
# Para Kaggle
ids <- test$id

# Convertir probabilidades 
pred_binaria <- ifelse(pred_prob_cart[, "Yes"] > 0.5, 1, 0)


submission <- data.frame(id = ids, Pobre = pred_clase)
# 1. Revisa estructura
str(submission)
```

##3.2 Template_CART

```{r}
write.csv
write.csv(submission, "C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller2/06-04-25_equipo4_cart.csv", 
          row.names = FALSE, 
          quote = FALSE)
```
