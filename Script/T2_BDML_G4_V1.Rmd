---
title: "Taller_2"
author: GARCIA BERNAL, ZAIRA ALEJANDRA RIVERA SANABRIA, LAURA SARIF JACOME VELASCO,
  NICOLAS VIAFARA MORALES, JORGE ELIECER
date: "2025-03-22"
output: html_document
---

# Problem set 2 - Predicting poverty

*El objetivo es predecir la pobreza a nivel de hogar.*

$$
Poor = I(Inc < Pl)
$$ donde I es una función indicadora que toma uno si los ingresos familiares están por debajo de un determinado umbral de pobreza

## 1. Introducción

La pobreza es un desafío político y social crucial en muchos países vulnerables, donde suele medirse mediante el gasto de consumo (Galvis Caballero, 2021). *Los Bosques Aleatorios (Random Forest) han demostrado alta precisión al clasificar los extremos del índice de riqueza, superando técnicas de regresión clásica*. Factores como la residencia regional y el nivel educativo son esenciales al diseñar intervenciones para mejorar los medios de vida (Okiabera, J. O., 2020). Para enfrentar la pobreza, se han implementado subsidios y transferencias monetarias. Sin embargo, los programas sociales universales también benefician a personas que no necesitan ayuda, impulsando el uso de pruebas de medios indirectas (PMT) basadas en variables socioeconómicas como el género y las condiciones de vivienda (Brown, Ravallion & van de Walle, 2018).

Este estudio implementó cinco algoritmos de clasificación —regresión lineal, logística, red elástica, Random Forest y boosting— para predecir la pobreza en Colombia, destacando el Random Forest por su robustez (Sohnesen et al., 2017). La estructura del trabajo incluye limpieza de datos, análisis de variables, predicción de ingresos y conclusiones, proporcionando una visión integral de los factores que influyen en la pobreza. 

## 2. Datos

### 2.1 Construcción de la muestra

El proceso de construcción de la muestra inicia con la carga de los paquetes necesarios en R, utilizando require("pacman") y p_load() para facilitar la instalación y gestión de herramientas esenciales para la manipulación y análisis de datos. Se emplean paquetes como tidyverse para la transformación de datos, glmnet para la implementación de algoritmos de regularización, caret para la creación de modelos predictivos, y MLmetrics para la evaluación del desempeño de los modelos.

A continuación, se cargan las bases de datos de entrenamiento y prueba, que contienen información sobre hogares (train_hogares.csv, test_hogares.csv) y personas (train_personas.csv, test_personas.csv). Se inicia el análisis exploratorio con la inspección de nombres de columnas y la selección de variables clave, como el identificador del hogar (id). En la base de hogares, se crea una nueva variable pobre_hand, que clasifica a los hogares en pobres y no pobres en función del ingreso per cápita y la línea de pobreza (Lp); Para la base de personas, se procesan los datos mediante la creación de nuevas variables, como mujer (indicador de género), mayor_edad (mayores de 18 años), afi_salud (afiliación a salud), y EducLevel (nivel educativo). Se reemplazan valores ausentes con valores adecuados y se consolidan los datos a nivel de hogar agrupando variables como el número de mujeres, mayores de edad y cotizantes en el hogar. Luego, se filtran los registros del jefe de hogar para capturar características específicas de este, como su nivel educativo y estado laboral, y se unen con la base agregada por hogar.

El siguiente paso consiste en la limpieza de la base de hogares, generando nuevas variables indicadoras sobre la tenencia de la vivienda (pagada, hipoteca, arriendo, usufructo, sin_titulo). Posteriormente, las bases de hogares y personas se combinan mediante el identificador id, consolidando la información en una única base de entrenamiento (train) y una de prueba (test). Para finalizar, se convierten variables clave en factores categóricos, como el dominio geográfico, el tipo de tenencia de la vivienda y los niveles educativos. Este procesamiento asegura que los datos sean adecuados para el análisis y modelado posterior, facilitando la interpretación de los resultados y la construcción de modelos predictivos eficientes.

```{r}
#Cargar los paquetes de trabajo
require("pacman")
p_load(tidyverse,   # tidy-data
       glmnet,      # To implement regularization algorithms. 
       caret,       # creating predictive models
       BiocManager,
       Metrics,
       readr,
       utils)

install.packages("MLmetrics") # To calculate metrics
require(MLmetrics)
library(httr)
```

```{r}
## 1. Carga de datos train hogares

# Definir URL del archivo Excel en GitHub
url_excel <- "https://raw.githubusercontent.com/GeorgeWton1986/T2_BDML/refs/heads/main/03_Stores/train_hogares.csv"

# Descargar el archivo temporalmente
temp_file <- tempfile(fileext = ".csv")
GET(url_excel, write_disk(temp_file, overwrite = TRUE))

# Leer el archivo CSV en un dataframe
train_hogares <- read_csv(temp_file)


## 2. Carga de datos train personas

# URL del archivo ZIP en GitHub
url_zip <- "https://github.com/GeorgeWton1986/T2_BDML/raw/refs/heads/main/03_Stores/train_personas.zip"

# Crear un archivo temporal para almacenar el ZIP
temp_zip <- tempfile(fileext = ".zip")

# Descargar el archivo ZIP desde GitHub
GET(url_zip, write_disk(temp_zip, overwrite = TRUE))
temp_dir <- tempfile()
dir.create(temp_dir)

# Extraer el contenido del ZIP
unzip(temp_zip, exdir = temp_dir)

# Leer el archivo CSV extraído
csv_personas1 <- file.path(temp_dir, "train_personas.csv")
train_personas <- read_csv(csv_personas1)

## 3. Carga de datos test hogares

# Definir URL del archivo Excel en GitHub
url_excel_test <- "https://raw.githubusercontent.com/GeorgeWton1986/T2_BDML/refs/heads/main/03_Stores/test_hogares.csv"

# Descargar el archivo temporalmente
temp_file <- tempfile(fileext = ".csv")
GET(url_excel_test, write_disk(temp_file, overwrite = TRUE))

# Leer el archivo CSV en un dataframe
test_hogares <- read_csv(temp_file)

## 4. Carga de datos test personas

# Definir URL del archivo Excel en GitHub
url_excel_test2 <- "https://raw.githubusercontent.com/GeorgeWton1986/T2_BDML/refs/heads/main/03_Stores/test_personas.csv"

# Descargar el archivo temporalmente
temp_file <- tempfile(fileext = ".csv")
GET(url_excel_test2, write_disk(temp_file, overwrite = TRUE))

# Leer el archivo CSV en un dataframe
test_personas <- read_csv(temp_file)

```


#### a) Exploración de Base Train Hogares

```{r}
#Nombre de las columnas de la base train_hogares
colnames(train_hogares)
```

```{r}
#Seleccion de la columnas id de hogares
train_hogares %>%
  select(id) %>%
  head()
```

```{r}
#Cantidad de hogares probres de la base train_hogares
table(train_hogares$Pobre)
```

```{r}
#Incluir una columna con la asignacion de 1 si el ingreso per capita hogar es menor a la linea de probreza y 0 en caso contrario
train_hogares <- train_hogares %>% 
  mutate(pobre_hand=ifelse(Ingpcug<Lp,1,0))
```

```{r}
#Representación en tabla de los resultado
table(train_hogares$Pobre,train_hogares$pobre_hand)
```

#### b) Exploración de Base Train Personas

```{r}
#Nombre de las columnas de la base train_personas
colnames(train_personas)
```

```{r}
#Selección de la columnas id y orden de los mienbros de la base personas
train_personas %>%
  select(id, Orden) %>%
  head()
```

```{r}
#Agrupa las personas por hogar y calculo del indicie de personas inactivas
train_personas_1<- train_personas %>%
  group_by(id)%>%
  summarize(h_inactivos=sum(Ina, na.rm = TRUE),
            h_pet=sum(Pet, na.rm = TRUE))%>%
  mutate(h_inactivosp=h_inactivos/h_pet) %>%
  ungroup()
```


#### c) Exploración de Base Test Hogares

```{r}
#Nombre de las columnas de la base test_hogares
colnames(test_hogares)
```

```{r}
#Selección de la columnas id y número de personas por hogar
test_hogares %>%
  select(id, Npersug) %>%
  head()
```

##B.2 Base Test Personas

```{r}
#Nombre de las columnas de la base test_personas

colnames(test_personas)
```

#1. Pre procesamiento

```{r}
#Pre procesamiento de la base Train_Personas
clear_train_personas <- train_personas %>% 
  mutate(mujer = ifelse(P6020==2,1,0),
  mayor_edad = ifelse(P6040 >= 18,1,0), #Mayores de edad
  H_Head = ifelse(P6050== 1, 1, 0), #Household head
  afi_salud = ifelse (P6090==1,1,0), #Afiliacion de salud
  afi_salud = ifelse (is.na(afi_salud),0,1), #Reemplazo de los NA
  EducLevel = ifelse(P6210==9,0,P6210), #Replace 9 with 0
  EducLevel = ifelse(is.na(EducLevel),0,EducLevel),#Reemplazo de los NA
  act_semana_pasada = ifelse(P6240 == 6,0,P6240),
  act_semana_pasada = ifelse(is.na(act_semana_pasada),0,act_semana_pasada), #Reemplazo de los NA
  t_trab_semanal = ifelse(is.na(P6426),0,1),
  cotizando = ifelse(P6920 == 3, 1, P6920), #Incluir los pensionados
  cotizando = ifelse(is.na(cotizando),0,cotizando),#Reemplazo de los NA
  ocupado = ifelse(is.na(Oc),0,1)) %>%
  select(id, Orden,mujer,mayor_edad,H_Head,afi_salud,EducLevel,act_semana_pasada,t_trab_semanal,cotizando,ocupado)

#Pre procesamiento de la base Test_Personas
clear_test_personas <- test_personas %>% 
  mutate(mujer = ifelse(P6020==2,1,0),
  mayor_edad = ifelse(P6040 >= 18,1,0), #Mayores de edad
  H_Head = ifelse(P6050== 1, 1, 0), #Household head
  afi_salud = ifelse (P6090==1,1,0), #Afiliacion de salud
  afi_salud = ifelse (is.na(afi_salud),0,1), #Reemplazo de los NA
  EducLevel = ifelse(P6210==9,0,P6210), #Replace 9 with 0
  EducLevel = ifelse(is.na(EducLevel),0,EducLevel),#Reemplazo de los NA
  act_semana_pasada = ifelse(P6240 == 6,0,P6240),
  act_semana_pasada = ifelse(is.na(act_semana_pasada),0,act_semana_pasada), #Reemplazo de los NA
  t_trab_semanal = ifelse(is.na(P6426),0,1),
  cotizando = ifelse(P6920 == 3, 1, P6920), #Incluir los pensionados
  cotizando = ifelse(is.na(cotizando),0,cotizando),#Reemplazo de los NA
  ocupado = ifelse(is.na(Oc),0,1)) %>%
  select(id, Orden,mujer,mayor_edad,H_Head,afi_salud,EducLevel,act_semana_pasada,t_trab_semanal,cotizando,ocupado)
```

```{r}
colnames(clear_train_personas)
```

```{r}
colnames(clear_test_personas)
```

##1.2 Argupar y unir Train Personas

```{r}
#Agrupar el entrenamiento de la base personas a nivel hogar y unir las bases de datos por medio de id.

summary_train_personas_nivel_hogar <- clear_train_personas %>% 
  group_by(id) %>% 
  summarize(nmujeres = sum(mujer,na.rm=TRUE),
            nmayor_edad = sum(mayor_edad,na.rm=TRUE),
            nafi_salud = sum(afi_salud, na.rm = TRUE),
            maxEducLevel = max(EducLevel,na.rm=TRUE),
            nt_trab_semanal = sum(t_trab_semanal,na.rm = TRUE),
            ncotizando = sum(cotizando,na.rm = TRUE),
            nocupados=sum(ocupado,na.rm=TRUE))

filter_train_personas_hogar<- clear_train_personas %>% 
                  filter(H_Head==1) %>% 
                  select(id,mujer,afi_salud,EducLevel,cotizando,ocupado) %>% 
                  rename(H_Head_mujer=mujer,
                         H_afi_salud = afi_salud,
                         H_Head_Educ_level=EducLevel,
                         H_cotizando = cotizando,
                         H_Head_ocupado=ocupado) %>% 
                    left_join(summary_train_personas_nivel_hogar)
```

```{r}
colnames(filter_train_personas_hogar)
```

##1.3 Argupar y unir Test Personas

```{r}
#Agrupar la prueba de la base personas a nivel hogar y unir las bases de datos por medio de id.


summary_test_personas_nivel_hogar <- clear_test_personas %>% 
  group_by(id) %>% 
  summarize(nmujeres = sum(mujer,na.rm=TRUE),
            nmayor_edad = sum(mayor_edad,na.rm=TRUE),
            nafi_salud = sum(afi_salud, na.rm = TRUE),
            maxEducLevel = max(EducLevel,na.rm=TRUE),
            nt_trab_semanal = sum(t_trab_semanal,na.rm = TRUE),
            ncotizando = sum(cotizando,na.rm = TRUE),
            nocupados=sum(ocupado,na.rm=TRUE))

filter_test_personas_hogar<- clear_test_personas %>% 
                  filter(H_Head==1) %>% 
                  select(id,mujer,afi_salud,EducLevel,cotizando,ocupado) %>% 
                  rename(H_Head_mujer=mujer,
                         H_afi_salud = afi_salud,
                         H_Head_Educ_level=EducLevel,
                         H_cotizando = cotizando,
                         H_Head_ocupado=ocupado) %>% 
                    left_join(summary_test_personas_nivel_hogar, by = "id")
```

```{r}
colnames(filter_test_personas_hogar)
```

##1.4 Base de trabajo Train Hogares

```{r}
clear_train_hogares<- train_hogares %>% 
  mutate(pagada= ifelse(P5090==1,1,0),
         hipoteca= ifelse(P5090==2,1,0),
         arriendo= ifelse(P5090==3,1,0),
         usufructo= ifelse(P5090==4,1,0),
         sin_titulo = ifelse(P5090==5,1,0)) %>% 
  select(id, Clase, Nper, Dominio,pagada, hipoteca, arriendo, usufructo, sin_titulo, Lp, Pobre)
```

##1.5 Base de trabajo Test Hogares

```{r}
clear_test_hogares<- test_hogares %>% 
  mutate(pagada= ifelse(P5090==1,1,0),
         hipoteca= ifelse(P5090==2,1,0),
         arriendo= ifelse(P5090==3,1,0),
         usufructo= ifelse(P5090==4,1,0),
         sin_titulo = ifelse(P5090==5,1,0)) %>% 
  select(id, Clase, Nper, Dominio, pagada, hipoteca, arriendo, usufructo, sin_titulo, Lp)
```

##1.6 Consolidar las BD Train y Test Hogares

```{r}
train<- clear_train_hogares %>% 
          left_join(filter_train_personas_hogar) %>% 
          select(-id) #no longer need id

test<- clear_test_hogares %>% 
          left_join(filter_test_personas_hogar)

```

##1.7 Conversion a factores

```{r}
train_factors<- train %>% 
  mutate(Dominio=factor(Dominio),
         pagada=factor(pagada,levels = c(0,1),labels = c("No","Yes")),
         hipoteca=factor(hipoteca,levels = c(0,1),labels = c("No","Yes")),
         arriendo=factor(arriendo,levels = c(0,1),labels = c("No","Yes")),
         usufructo=factor(usufructo,levels = c(0,1),labels = c("No","Yes")),
         sin_titulo=factor(sin_titulo,levels = c(0,1),labels = c("No","Yes")),
         Pobre=factor(Pobre,levels = c(0,1),labels = c("No", "Yes")),
         H_Head_Educ_level = factor(H_Head_Educ_level, levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria')),
         maxEducLevel = factor(maxEducLevel,levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria') ))

test_factors<- test %>% 
  mutate(Dominio=factor(Dominio),
         pagada=factor(pagada,levels = c(0,1),labels = c("No","Yes")),
         hipoteca=factor(hipoteca,levels = c(0,1),labels = c("No","Yes")),
         arriendo=factor(arriendo,levels = c(0,1),labels = c("No","Yes")),
         usufructo=factor(usufructo,levels = c(0,1),labels = c("No","Yes")),
         sin_titulo=factor(sin_titulo,levels = c(0,1),labels = c("No","Yes")),
         H_Head_Educ_level = factor(H_Head_Educ_level, levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria')),
         maxEducLevel = factor(maxEducLevel,levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria') ))

```

## 3. Modelos y resultados

### 3.1 Modelo Elastic Net

```{r}
ctrl<- trainControl(method = "cv",
                    number = 5,
                    classProbs = TRUE,
                    savePredictions = T)
```

```{r}
#Modelo Elastic Net

set.seed(123)

mod_1_EN <- train(Pobre~.,#Modelo 1 Elastic Net
    data=train_factors,
    metric = "Accuracy",
    method = "glmnet",
    trControl = ctrl,
    tuneGrid=expand.grid(
              alpha = seq(0,1,by=.2),
              lambda =10^seq(10, -2, length = 10)
    )
               
)
```

##2.2 Resultado_EN

```{r}
mod_1_EN
```

##2.2 Modelo F1

```{r}
p_load(Metrics)
fiveStats <- function(...)  c(prSummary(...))  


ctrl<- trainControl(method = "cv",
                    number = 5,
                    classProbs = TRUE,
                    summaryFunction = fiveStats,
                    savePredictions = TRUE)
```

```{r}

set.seed(123)
mod_1_F <- train(Pobre~.,
    data=train_factors,
    metric = "F",
    method = "glmnet",
    trControl = ctrl,
    family="binomial",
    tuneGrid=expand.grid(
              alpha = seq(0,1,by=.5),
              lambda =10^seq(-1, -3, length = 10)
    )

)
```

##2.4 Resultado_F1

```{r}
mod_1_F
```

### 3.2 Modelo Logit

```{r}
#Calculo de los estimadores Logit
mod_1_logit<- glm(Pobre~., 
                 data = train_factors, 
                 family = "binomial")

```

##3.2 Resultados Estimadores Logit

```{r}
summary(mod_1_logit,type="text")
```

##3.3 Probabilidad Logit

```{r}
#Calculo de probabilidades
prob_logit<- train_factors %>% 
  mutate(prob_hat=predict(mod_1_logit,
                          newdata = train_factors, 
                          type = "response"), #type = "response" gives the predicted probabilities.
         prob_logodds = predict(mod_1_logit,
                          newdata = train_factors, 
                          type = "link"), #type = "link" gives the predicted log-odds.
         prob2 = predict(mod_1_logit,
                          newdata = train_factors))


```

## 3.4 Resultado Probabilidad Logit

```{r}
head(prob_logit %>% 
       select(Pobre,prob_hat, ))
```

## 3.5 Clasificador Logit

```{r}

rule <- 1/2 # Bayes Rule

pred_pobre<- prob_logit %>% 
  mutate(pred_pobre=ifelse(prob_hat>rule,1,0))    ## prediccion de pobre

head(prob_logit %>%
       select(Pobre,prob_hat,pred_pobre))

```

##3.6 Accuracy Logit

```{r}

A <- with(prob_logit,table(Pobre,pred_pobre))

Accuracy <- (A[1]+ A[4])/(A[1]+ A[2] + A[3]+  A[4])
Accuracy

```

##3.7 Entrenamiento Fuera de muestra Modelo_Logit

```{r}
ctrl<- trainControl(method = "cv",
                    number = 5,
                    classProbs = TRUE,
                    savePredictions = TRUE,
                    verbose=T
                    )
```

##3.8 Entrenamiento modelo 2

```{r}
set.seed(123)
mod_2_logit <- train(Pobre~. ,
                       data = train_factors, 
                       method = "glm",
                       family = "binomial",
                       trControl = ctrl
                       )

mod_2_logit
```

##3.9 Rendimiento del test

```{r}
print(paste("Mean accuracy: ",mean(mod_2_logit$resample$Accuracy)))
logit_accuracy<-mod_2_logit$results$Accuracy
logit_accuracy
```

##3.10 Predición/Clasificacion

```{r}
#Evaluacion en el Test Set
predictTest_logit <- test_factors   %>% 
  mutate(pred_test_prob = predict(mod_2_logit,
          newdata = test_factors,
          type = "prob"), #Prediccion con probabilidades
  pred_test_raw = predict(mod_2_logit,
                 newdata = test_factors,
                 type = "raw"))%>% 
  select(id,pred_test_raw)

head(predict_logit)

```

```{r}
predictTest_logit<- predictTest_logit %>% 
                  mutate(Pobre_test=ifelse(pred_test_raw=="Yes",1,0)) %>% 
                  select(id,Pobre_test)

head(predictTest_logit) 
```

```{r}
nrow(predictTest_logit)
str(predictTest_logit)
head(predictTest_logit)
```

##3.11 Template_Logit

```{r}
write.csv(predictTest_logit, "/Users/jorgeviafara/Library/CloudStorage/OneDrive-Personal/MAESTRIA EN ECONOMIA/01 MATERIAS MECA/4107 BIG DATA/T2_BDML_personal/sample_equipo4_Logit.csv", row.names = FALSE)
```

#3 Predicciones

##3.1 Predicción_EN

```{r}

predictSample_EN <- test_factors   %>% 
  mutate(pobre_lab = predict(mod_1_EN, 
                             newdata = test_factors, 
                             type = "raw"))%>% 
  select(id,pobre_lab)

head(predictSample_EN)

```

```{r}
predictSample_EN<- predictSample_EN %>% 
                  mutate(pobre=ifelse(pobre_lab=="Yes",1,0)) %>% 
                  select(id,pobre)
head(predictSample_EN) 
```

```{r}
nrow(predictSample_EN)

str(predictSample_EN)
head(predictSample_EN)
```

##3.2 Template_EN

```{r}
write.csv(predictSample_EN, "/Users/jorgeviafara/Library/CloudStorage/OneDrive-Personal/MAESTRIA EN ECONOMIA/01 MATERIAS MECA/4107 BIG DATA/T2_BDML_personal/sample_equipo4_EN.csv", row.names = FALSE)

```

```{r}
str(predictSample_EN)  # Verifica estructura
summary(predictSample_EN)  # Estadísticas básicas
head(predictSample_EN, 10)  # Muestra las primeras 10 filas
```
