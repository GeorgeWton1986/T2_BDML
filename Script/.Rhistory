# Carga de BD extraida
train_personas <- read_csv("03_Stores/train_personas.csv")
# Definir URL del archivo Excel en GitHub (enlace "raw")
url_excel <- "https://raw.githubusercontent.com/GeorgeWton1986/T2_BDML/refs/heads/main/03_Stores/train_hogares.csv"
# Descargar el archivo temporalmente
temp_file <- tempfile(fileext = ".csv")
GET(url_csv, write_disk(temp_file, overwrite = TRUE))
library(httr)
# Definir URL del archivo Excel en GitHub (enlace "raw")
url_excel <- "https://raw.githubusercontent.com/GeorgeWton1986/T2_BDML/refs/heads/main/03_Stores/train_hogares.csv"
# Descargar el archivo temporalmente
temp_file <- tempfile(fileext = ".csv")
GET(url_csv, write_disk(temp_file, overwrite = TRUE))
# Definir URL del archivo Excel en GitHub (enlace "raw")
url_excel <- "https://raw.githubusercontent.com/GeorgeWton1986/T2_BDML/refs/heads/main/03_Stores/train_hogares.csv"
# Descargar el archivo temporalmente
temp_file <- tempfile(fileext = ".csv")
GET(url_excel, write_disk(temp_file, overwrite = TRUE))
# Leer el archivo CSV en un dataframe
train_hogares <- read_csv(temp_file)
# Carga de datos train
# Definir URL del archivo Excel en GitHub (enlace "raw")
url_excel <- "https://raw.githubusercontent.com/GeorgeWton1986/T2_BDML/refs/heads/main/03_Stores/train_hogares.csv"
# Descargar el archivo temporalmente
temp_file <- tempfile(fileext = ".csv")
GET(url_excel, write_disk(temp_file, overwrite = TRUE))
# Leer el archivo CSV en un dataframe
train_hogares <- read_csv(temp_file)
# URL del archivo ZIP en GitHub
url_zip <- "https://github.com/GeorgeWton1986/T2_BDML/raw/refs/heads/main/03_Stores/train_personas.zip"
# Crear un archivo temporal para almacenar el ZIP
temp_zip <- tempfile(fileext = ".zip")
# Descargar el archivo ZIP desde GitHub
GET(url_zip, write_disk(temp_zip, overwrite = TRUE))
temp_dir <- tempfile()
dir.create(temp_dir)
# Extraer el contenido del ZIP
unzip(temp_zip, exdir = temp_dir)
# Leer el archivo CSV extraído
csv_personas1 <- file.path(temp_dir, "train_personas.csv")
train_personas <- read_csv(csv_personas1)
View(train_hogares)
View(train_personas)
## 3. Carga de datos test hogares
# Definir URL del archivo Excel en GitHub
url_excel_test <- "https://raw.githubusercontent.com/GeorgeWton1986/T2_BDML/refs/heads/main/03_Stores/test_hogares.csv"
# Descargar el archivo temporalmente
temp_file <- tempfile(fileext = ".csv")
GET(url_excel, write_disk(temp_file, overwrite = TRUE))
# Leer el archivo CSV en un dataframe
test_hogares <- read_csv(temp_file)
## 3. Carga de datos test hogares
# Definir URL del archivo Excel en GitHub
url_excel_test <- "https://raw.githubusercontent.com/GeorgeWton1986/T2_BDML/refs/heads/main/03_Stores/test_hogares.csv"
# Descargar el archivo temporalmente
temp_file <- tempfile(fileext = ".csv")
GET(url_excel_test, write_disk(temp_file, overwrite = TRUE))
# Leer el archivo CSV en un dataframe
test_hogares <- read_csv(temp_file)
View(test_hogares)
## 4. Carga de datos test personas
# Definir URL del archivo Excel en GitHub
url_excel_test2 <- "https://raw.githubusercontent.com/GeorgeWton1986/T2_BDML/refs/heads/main/03_Stores/test_personas.csv"
# Descargar el archivo temporalmente
temp_file <- tempfile(fileext = ".csv")
GET(url_excel_test2, write_disk(temp_file, overwrite = TRUE))
# Leer el archivo CSV en un dataframe
test_personas <- read_csv(temp_file)
#Asignar y cargar las bases de datos Entrenamiento
train_hogares<-read.csv("C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller2/train_hogares.csv")
train_personas<-read.csv("C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller2/train_personas.csv")
#Nombre de las columnas de la base train_hogares
colnames(train_hogares)
#Asignar y cargar las bases de datos prueba
test_hogares<-read.csv("C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller2/test_hogares.csv")
test_personas<-read.csv("C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller2/test_personas.csv")
#Seleccion de la columnas id de hogares
train_hogares %>%
select(id) %>%
head()
#Cargar los paquetes de trabajo
require("pacman")
p_load(tidyverse, # tidy-data
glmnet, # To implement regularization algorithms.
caret, # creating predictive models
BiocManager,
Metrics
)
install.packages("MLmetrics") # To calculate metrics
require(MLmetrics)
#Nombre de las columnas de la base train_hogares
colnames(train_hogares)
#Seleccion de la columnas id de hogares
train_hogares %>%
select(id) %>%
head()
#Cantidad de hogares probres de la base train_hogares
table(train_hogares$Pobre)
#Incluir una columna con la asignacion de 1 si el ingreso per capita hogar es menor a la linea de probreza y 0 en caso contrario
train_hogares <- train_hogares %>%
mutate(pobre_hand=ifelse(Ingpcug<Lp,1,0))
View(train_hogares)
#Incluir una columna con la asignacion de 1 si el ingreso per capita hogar es menor a la linea de probreza y 0 en caso contrario
train_hogares <- train_hogares %>%
mutate(pobre_hand=ifelse(Ingpcug<Lp,1,0))
#Representación en tabla de los resultado
table(train_hogares$Pobre,train_hogares$pobre_hand)
#Nombre de las columnas de la base train_personas
colnames(train_personas)
#Selección de la columnas id y orden de los mienbros de la base personas
train_personas %>%
select(id, Orden) %>%
head()
#Agrupa las personas por hogar y calculo del indicie de personas inactivas
train_personas_1<- train_personas %>%
group_by(id)%>%
summarize(h_inactivos=sum(Ina, na.rm = TRUE),
h_pet=sum(Pet, na.rm = TRUE))%>%
mutate(h_inactivosp=h_inactivos/h_pet) %>%
ungroup()
View(test_personas)
View(train_personas_1)
#Nombre de las columnas de la base test_hogares
colnames(test_hogares)
#Selección de la columnas id y número de personas por hogar
test_hogares %>%
select(id, Npersug) %>%
head()
#Nombre de las columnas de la base test_personas
colnames(test_personas)
#Pre procesamiento de la base Train_Personas
clear_train_personas <- train_personas %>%
mutate(mujer = ifelse(P6020==2,1,0),
mayor_edad = ifelse(P6040 >= 18,1,0), #Mayores de edad
H_Head = ifelse(P6050== 1, 1, 0), #Household head
afi_salud = ifelse (P6090==1,1,0), #Afiliacion de salud
afi_salud = ifelse (is.na(afi_salud),0,1), #Reemplazo de los NA
EducLevel = ifelse(P6210==9,0,P6210), #Replace 9 with 0
EducLevel = ifelse(is.na(EducLevel),0,EducLevel),#Reemplazo de los NA
act_semana_pasada = ifelse(P6240 == 6,0,P6240),
act_semana_pasada = ifelse(is.na(act_semana_pasada),0,act_semana_pasada), #Reemplazo de los NA
t_trab_semanal = ifelse(is.na(P6426),0,1),
cotizando = ifelse(P6920 == 3, 1, P6920), #Incluir los pensionados
cotizando = ifelse(is.na(cotizando),0,cotizando),#Reemplazo de los NA
ocupado = ifelse(is.na(Oc),0,1)) %>%
select(id, Orden,mujer,mayor_edad,H_Head,afi_salud,EducLevel,act_semana_pasada,t_trab_semanal,cotizando,ocupado)
#Pre procesamiento de la base Test_Personas
clear_test_personas <- test_personas %>%
mutate(mujer = ifelse(P6020==2,1,0),
mayor_edad = ifelse(P6040 >= 18,1,0), #Mayores de edad
H_Head = ifelse(P6050== 1, 1, 0), #Household head
afi_salud = ifelse (P6090==1,1,0), #Afiliacion de salud
afi_salud = ifelse (is.na(afi_salud),0,1), #Reemplazo de los NA
EducLevel = ifelse(P6210==9,0,P6210), #Replace 9 with 0
EducLevel = ifelse(is.na(EducLevel),0,EducLevel),#Reemplazo de los NA
act_semana_pasada = ifelse(P6240 == 6,0,P6240),
act_semana_pasada = ifelse(is.na(act_semana_pasada),0,act_semana_pasada), #Reemplazo de los NA
t_trab_semanal = ifelse(is.na(P6426),0,1),
cotizando = ifelse(P6920 == 3, 1, P6920), #Incluir los pensionados
cotizando = ifelse(is.na(cotizando),0,cotizando),#Reemplazo de los NA
ocupado = ifelse(is.na(Oc),0,1)) %>%
select(id, Orden,mujer,mayor_edad,H_Head,afi_salud,EducLevel,act_semana_pasada,t_trab_semanal,cotizando,ocupado)
colnames(clear_train_personas)
colnames(clear_test_personas)
#Agrupar el entrenamiento de la base personas a nivel hogar y unir las bases de datos por medio de id.
summary_train_personas_nivel_hogar <- clear_train_personas %>%
group_by(id) %>%
summarize(nmujeres = sum(mujer,na.rm=TRUE),
nmayor_edad = sum(mayor_edad,na.rm=TRUE),
nafi_salud = sum(afi_salud, na.rm = TRUE),
maxEducLevel = max(EducLevel,na.rm=TRUE),
nt_trab_semanal = sum(t_trab_semanal,na.rm = TRUE),
ncotizando = sum(cotizando,na.rm = TRUE),
nocupados=sum(ocupado,na.rm=TRUE))
filter_train_personas_hogar<- clear_train_personas %>%
filter(H_Head==1) %>%
select(id,mujer,afi_salud,EducLevel,cotizando,ocupado) %>%
rename(H_Head_mujer=mujer,
H_afi_salud = afi_salud,
H_Head_Educ_level=EducLevel,
H_cotizando = cotizando,
H_Head_ocupado=ocupado) %>%
left_join(summary_train_personas_nivel_hogar)
colnames(filter_train_personas_hogar)
#Agrupar la prueba de la base personas a nivel hogar y unir las bases de datos por medio de id.
summary_test_personas_nivel_hogar <- clear_test_personas %>%
group_by(id) %>%
summarize(nmujeres = sum(mujer,na.rm=TRUE),
nmayor_edad = sum(mayor_edad,na.rm=TRUE),
nafi_salud = sum(afi_salud, na.rm = TRUE),
maxEducLevel = max(EducLevel,na.rm=TRUE),
nt_trab_semanal = sum(t_trab_semanal,na.rm = TRUE),
ncotizando = sum(cotizando,na.rm = TRUE),
nocupados=sum(ocupado,na.rm=TRUE))
filter_test_personas_hogar<- clear_test_personas %>%
filter(H_Head==1) %>%
select(id,mujer,afi_salud,EducLevel,cotizando,ocupado) %>%
rename(H_Head_mujer=mujer,
H_afi_salud = afi_salud,
H_Head_Educ_level=EducLevel,
H_cotizando = cotizando,
H_Head_ocupado=ocupado) %>%
left_join(summary_test_personas_nivel_hogar, by = "id")
clear_train_hogares<- train_hogares %>%
mutate(pagada= ifelse(P5090==1,1,0),
hipoteca= ifelse(P5090==2,1,0),
arriendo= ifelse(P5090==3,1,0),
usufructo= ifelse(P5090==4,1,0),
sin_titulo = ifelse(P5090==5,1,0)) %>%
select(id, Clase, Nper, Dominio,pagada, hipoteca, arriendo, usufructo, sin_titulo, Lp, Pobre)
clear_test_hogares<- test_hogares %>%
mutate(pagada= ifelse(P5090==1,1,0),
hipoteca= ifelse(P5090==2,1,0),
arriendo= ifelse(P5090==3,1,0),
usufructo= ifelse(P5090==4,1,0),
sin_titulo = ifelse(P5090==5,1,0)) %>%
select(id, Clase, Nper, Dominio, pagada, hipoteca, arriendo, usufructo, sin_titulo, Lp)
train<- clear_train_hogares %>%
left_join(filter_train_personas_hogar) %>%
select(-id) #no longer need id
test<- clear_test_hogares %>%
left_join(filter_test_personas_hogar)
train_factors<- train %>%
mutate(Dominio=factor(Dominio),
pagada=factor(pagada,levels = c(0,1),labels = c("No","Yes")),
hipoteca=factor(hipoteca,levels = c(0,1),labels = c("No","Yes")),
arriendo=factor(arriendo,levels = c(0,1),labels = c("No","Yes")),
usufructo=factor(usufructo,levels = c(0,1),labels = c("No","Yes")),
sin_titulo=factor(sin_titulo,levels = c(0,1),labels = c("No","Yes")),
Pobre=factor(Pobre,levels = c(0,1),labels = c("No", "Yes")),
H_Head_Educ_level = factor(H_Head_Educ_level, levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria')),
maxEducLevel = factor(maxEducLevel,levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria') ))
test_factors<- test %>%
mutate(Dominio=factor(Dominio),
pagada=factor(pagada,levels = c(0,1),labels = c("No","Yes")),
hipoteca=factor(hipoteca,levels = c(0,1),labels = c("No","Yes")),
arriendo=factor(arriendo,levels = c(0,1),labels = c("No","Yes")),
usufructo=factor(usufructo,levels = c(0,1),labels = c("No","Yes")),
sin_titulo=factor(sin_titulo,levels = c(0,1),labels = c("No","Yes")),
H_Head_Educ_level = factor(H_Head_Educ_level, levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria')),
maxEducLevel = factor(maxEducLevel,levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria') ))
View(train_factors)
#Calculo de los estimadores Logit
mod_1_logit<- glm(Pobre~.,
data = train_factors,
family = "binomial")
summary(mod_1_logit,type="text")
#Calculo de probabilidades
prob_logit<- train_factors %>%
mutate(prob_hat=predict(mod_1_logit,
newdata = train_factors,
type = "response"))
head(prob_logit %>%
select(Pobre,prob_hat))
rule <- 0.4 # Bayes Rule
prob_logit<- prob_logit %>%
mutate(pred_pobre=ifelse(prob_hat>rule,1,0))    ## prediccion de pobre (0) No pobre y (1) Pobre
head(prob_logit %>%
select(Pobre,prob_hat,pred_pobre))
# Convertir la variable Pred_pobre a factor con etiquetas descriptivas
prob_logit$pred_pobre_factor <- factor(prob_logit$pred_pobre,
levels = c(0, 1),
labels = c("No Pobre", "Pobre"))
#Creacion de una matriz de confuncion
#           Predicho
# Real       0    1
#       0   [TN] [FP]
#       1   [FN] [TP]
#Matriz de confusión
A <- with(prob_logit,table(Pobre,pred_pobre_factor))
# Mostrar matriz de confusión
print("Matriz de confusión:")
print(A)
# Explicacion de valores matriz de confusion
TN_train <- A[1]  # Verdaderos Negativos
FP_train <- A[2]  # Falsos Positivos
FN_train <- A[3]  # Falsos Negativos
TP_train <- A[4]  # Verdaderos Positivos
# Crear tabla de conteos
counts_table <- data.frame(
Categoría = c("Verdaderos Negativos (TN)", "Falsos Positivos (FP)",
"Falsos Negativos (FN)", "Verdaderos Positivos (TP)"),
Conteo = c(TN_train, FP_train, FN_train, TP_train)
)
print(counts_table)
#Métricas derivadas:
# Exactitud (Accuracy): (TP + TN) / (TP + TN + FP + FN)
# Proporción de predicciones correctas.
# Precisión (Precision): TP / (TP + FP)
# De todos los casos predichos como "Pobres", ¿cuántos realmente lo son?
# Sensibilidad/Recall: TP / (TP + FN)
# De todos los casos realmente "Pobres", ¿cuántos identificamos correctamente?
# Especificidad: TN / (TN + FP)
# De todos los casos realmente "No pobres", ¿cuántos identificamos correctamente?
# F1-Score: 2 * (Precisión * Recall) / (Precisión + Recall)
# Media armónica de precisión y recall.
# Accuracy
accuracy_train <- (TN_train+ TP_train) / (TN_train + FP_train + FN_train + TP_train)
# Precisión
precision_train <- TP_train / (TP_train + FP_train)
# Recall (Sensibilidad)
recall_train <- TP_train / (TP_train + FN_train)
# Especificidad
specificity_train <- TN_train / (TN_train + FP_train)
# F1 Score
f1_score_train <- 2 * (precision_train * recall_train) / (precision_train + recall_train)
# Error Rate (Tasa de error)
error_rate_train <- 1 - accuracy_train
# Crear tabla de métricas
metrics_table_mod_1_log <- data.frame(
metrica_train = c("Accuracy (Exactitud)", "Precision (Precisión)", "Recall (Sensibilidad)",
"Specificity (Especificidad)", "F1 Score", "Error Rate (Tasa de error)"),
Valor = c(accuracy_train, precision_train, recall_train, specificity_train, f1_score_train, error_rate_train),
Descripción = c(
"Proporción total de predicciones correctas",
"De los predichos como pobres, cuántos realmente lo son",
"De los realmente pobres, cuántos fueron identificados correctamente",
"De los realmente no pobres, cuántos fueron identificados correctamente",
"Media armónica entre precisión y recall",
"Proporción de predicciones incorrectas"
)
)
# Mostrar tabla
print(metrics_table_mod_1_log)
ctrl<- trainControl(method = "cv",
number = 5,
classProbs = TRUE,
savePredictions = TRUE,
verbose=T
)
set.seed(123)
mod_2_logit <- train(Pobre~. ,
data = train_factors,
method = "glm",
family = "binomial",
trControl = ctrl,
metric = "Accuracy"
)
# Ver resultados
print(mod_2_logit)
summary(mod_2_logit)
# Ver predicciones por cada fold
head(mod_2_logit$pred)
#Matriz de confusion del modelo de entrenamiento
B <- confusionMatrix(mod_2_logit)
B <- B$table
# Explicacion de valores matriz de confusion
TN_train_cv <- B[1,1]  # Verdaderos Negativos
FP_train_cv <- B[2,1]  # Falsos Positivos
FN_train_cv <- B[1,2]  # Falsos Negativos
TP_train_cv <- B[2,2]  # Verdaderos Positivos
# Calcular métricas
accuracy_train_cv <- (TN_train_cv + TP_train_cv) / (TN_train_cv + FP_train_cv + FN_train_cv + TP_train_cv)
precision_train_cv <- TP_train_cv / (TP_train_cv + FP_train_cv)
recall_train_cv <- TP_train_cv / (TP_train_cv + FN_train_cv)
specificity_train_cv <- TN_train_cv / (TN_train_cv + FP_train_cv)
f1_score_train_cv <- 2 * (precision_train_cv * recall_train_cv) / (precision_train_cv + recall_train_cv)
error_rate_train_cv <- 1 - accuracy_train_cv
# Crear un data frame con los resultados
metrics_table_mod_2_log <- data.frame(
metrica_train_cv = c("Accuracy (Exactitud)", "Precision (Precisión)", "Recall (Sensibilidad)",
"Specificity (Especificidad)", "F1 Score", "Error Rate (Tasa de error)"),
Valor = c(accuracy_train_cv, precision_train_cv, recall_train_cv, specificity_train_cv, f1_score_train_cv, error_rate_train_cv)
)
print(metrics_table_mod_2_log)
# Importancia de variables
importancia <- varImp(mod_2_logit, scale = TRUE)
print(importancia)
plot(importancia, top = 20, main = "Las variables más importantes")
#Prediccion el Test Set
predictTest_logit <- test_factors %>%
mutate(
prob_pobre = predict(mod_2_logit,
newdata = test_factors,
type = "prob")[,"Yes"],# Probabilidad de ser "Pobre" ("Yes")
pred_pobre_cat = predict(mod_2_logit,
newdata = test_factors,
type = "raw"), # Predicción categórica (Yes/No)
pred_pobre = ifelse(pred_pobre_cat == "Yes", 1, 0)# Predicción numérica (1/0)
)
# Resumen
summary(predictTest_logit$prob_pobre)
table(predictTest_logit$pred_pobre_cat)
table(predictTest_logit$pred_pobre)
# Guardar los resultados
resultados_prediccion<- predictTest_logit %>%
select(id, pred_pobre)
# Ver las primeras filas de los resultados
head(resultados_prediccion)
# Generación de predicciones
predictTest_logit <- test_factors %>%
mutate(
prob_pobre = predict(mod_2_logit, newdata = test_factors, type = "prob")[,"Yes"],
pred_pobre_cat = predict(mod_2_logit, newdata = test_factors, type = "raw"),
pred_pobre = ifelse(pred_pobre_cat == "Yes", 1, 0)
)
# Distribucion de probabilidades predichas
hist(predictTest_logit$prob_pobre,
main = "Distribución de probabilidades",
xlab = "Probabilidad de ser clasificado como pobre",
col = "lightblue",
border = "white",
breaks = 20)  # Puedes ajustar el número de rangos
# Proporción de clases predichas
prop_clases <- prop.table(table(predictTest_logit$pred_pobre))
print(prop_clases)
# Visualizar proporción de clases en un gráfico de barras
barplot(prop_clases,
main = "Proporción de clases predichas",
xlab = "Clase (0 = No pobre, 1 = Pobre)",
ylab = "Proporción",
col = c("lightgreen", "coral"),
names.arg = c("No pobre", "Pobre"),
ylim = c(0, 1))
# Agregar etiquetas de porcentaje
text(x = 1:length(prop_clases),
y = prop_clases + 0.05,
labels = paste0(round(prop_clases * 100, 1), "%"),
cex = 0.8)
# AHORA puedes guardar solo las columnas necesarias para la entrega
resultados_prediccion <- predictTest_logit %>%
select(id, pred_pobre)
# Ver las primeras filas de los resultados
head(resultados_prediccion)
# Fijar semilla
set.seed(123)
# Resumen de los datos entrenamiento
summary(train_factors)
# Cross validation- entrenamiento fuera de muestra
cv10<- trainControl(number = 5, method ="cv")
# Hiperparámetros
tunegrid_rf<-expand.grid(mtry=c(2,3,4,5, 8), #Predictores aleatorios en cada división                                                del árbol
splitrule= "gini", ##Cambiar por gini y revisar
min.node.size=c(1,2,3,6)) #Tamaño mínimo de los nodos
rforest<-train(Pobre~. ,
data=train_factors,
trControl = cv10,
metric = "RMSE",
tuneGrid = tunegrid_rf,
method ="ranger")
rforest <- train(Pobre~. ,
data = train_factors,
method ="ranger",
trControl = cv10,
metric = "ROC",
tuneGrid = mtry_grid,
ntre = 500
)
# Fijar semilla
set.seed(123)
# Resumen de los datos entrenamiento
summary(train_factors)
# Cross validation- entrenamiento fuera de muestra
cv10<- trainControl(number = 5, method ="cv")
randomforest <- train(Pobre~. ,
data = train_factors,
method ="ranger",
trControl = crossval,
tuneGrid = expand.grid(mtry = 4, splitrule = "gini", min.node.size = 1),
num.trees = 500
)
randomforest <- train(Pobre~. ,
data = train_factors,
method ="ranger",
trControl = crossval,
tuneGrid = expand.grid(mtry = 4, splitrule = "gini", min.node.size = 1),
num.trees = 500
)
# Fijar semilla
set.seed(123)
# Resumen de los datos entrenamiento
summary(train_factors)
# Cross validation- entrenamiento fuera de muestra
crossval<- trainControl(number = 5, method ="cv")
randomforest <- train(Pobre~. ,
data = train_factors,
method ="ranger",
trControl = crossval,
tuneGrid = expand.grid(mtry = 4, splitrule = "gini", min.node.size = 1),
num.trees = 500
)
View(test_factors)
randomforest
# Calcular probabilidades de ser pobre
predictions <- predict(randomforest, newdata = test_factors)
# Criterio de Bayes para clasificación, 1 si es pobre y 0 no es pobre
pred_class <- ifelse(predictions > 0.5, 1, 0)
# Crear una tabla con los valores reales y predichos
tabla_predicciones <- data.frame(
ID = 1:nrow(test_factor),  # Identificador de cada observación
Pobreza_Real = test_factor$pobreza,  # Valores reales de pobreza
Probabilidad_Pobreza = predictions,  # Probabilidad estimada de ser pobre
Pobreza_Predicha = pred_class  # Clasificación final (0 o 1)
)
# Calcular probabilidades de ser pobre
predictions <- predict(randomforest, newdata = test_factors)
# Criterio de Bayes para clasificación, 1 si es pobre y 0 no es pobre
pred_class <- ifelse(predictions > 0.5, 1, 0)
# Crear una tabla con los valores reales y predichos
tabla_predicciones <- data.frame(
ID = 1:nrow(test_factors),  # Identificador de cada observación
Pobreza_Real = test_factors$pobreza,  # Valores reales de pobreza
Probabilidad_Pobreza = predictions,  # Probabilidad estimada de ser pobre
Pobreza_Predicha = pred_class  # Clasificación final (0 o 1)
)
# Calcular probabilidades de ser pobre
predictions <- predict(randomforest, newdata = test_factors, type = "prob")[, 2]
# Calcular probabilidades de ser pobre
predictions <- predict(randomforest, data = test_factors)$predictions[, 2]  # Probabilidad de ser pobre
# 1. Calcular probabilidades de ser pobre
predictions <- predict(randomforest, newdata = test_factors, type = "prob")[, 2]  # Probabilidad de ser pobre
View(randomforest)
