"Media armónica entre precisión y recall",
"Proporción de predicciones incorrectas"
)
)
# Mostrar tabla
print(metrics_table_mod_1_log)
ctrl<- trainControl(method = "cv",
number = 5,
classProbs = TRUE,
savePredictions = TRUE,
verbose=T
)
set.seed(123)
mod_2_logit <- train(Pobre~. ,
data = train_factors,
method = "glm",
family = "binomial",
trControl = ctrl,
metric = "Accuracy"
)
# Ver resultados
print(mod_2_logit)
summary(mod_2_logit)
# Ver predicciones por cada fold
head(mod_2_logit$pred)
#Matriz de confusion del modelo de entrenamiento
B <- confusionMatrix(mod_2_logit)
B <- B$table
# Explicacion de valores matriz de confusion
TN_train_cv <- B[1,1]  # Verdaderos Negativos
FP_train_cv <- B[2,1]  # Falsos Positivos
FN_train_cv <- B[1,2]  # Falsos Negativos
TP_train_cv <- B[2,2]  # Verdaderos Positivos
# Calcular métricas
accuracy_train_cv <- (TN_train_cv + TP_train_cv) / (TN_train_cv + FP_train_cv + FN_train_cv + TP_train_cv)
precision_train_cv <- TP_train_cv / (TP_train_cv + FP_train_cv)
recall_train_cv <- TP_train_cv / (TP_train_cv + FN_train_cv)
specificity_train_cv <- TN_train_cv / (TN_train_cv + FP_train_cv)
f1_score_train_cv <- 2 * (precision_train_cv * recall_train_cv) / (precision_train_cv + recall_train_cv)
error_rate_train_cv <- 1 - accuracy_train_cv
# Crear un data frame con los resultados
metrics_table_mod_2_log <- data.frame(
metrica_train_cv = c("Accuracy (Exactitud)", "Precision (Precisión)", "Recall (Sensibilidad)",
"Specificity (Especificidad)", "F1 Score", "Error Rate (Tasa de error)"),
Valor = c(accuracy_train_cv, precision_train_cv, recall_train_cv, specificity_train_cv, f1_score_train_cv, error_rate_train_cv)
)
print(metrics_table_mod_2_log)
# Importancia de variables
importancia <- varImp(mod_2_logit, scale = TRUE)
print(importancia)
plot(importancia, top = 20, main = "Las variables más importantes")
#Prediccion el Test Set
predictTest_logit <- test_factors %>%
mutate(
prob_pobre = predict(mod_2_logit,
newdata = test_factors,
type = "prob")[,"Yes"],# Probabilidad de ser "Pobre" ("Yes")
pred_pobre_cat = predict(mod_2_logit,
newdata = test_factors,
type = "raw"), # Predicción categórica (Yes/No)
pred_pobre = ifelse(pred_pobre_cat == "Yes", 1, 0)# Predicción numérica (1/0)
)
# Resumen
summary(predictTest_logit$prob_pobre)
table(predictTest_logit$pred_pobre_cat)
table(predictTest_logit$pred_pobre)
# Guardar los resultados
resultados_prediccion<- predictTest_logit %>%
select(id, pred_pobre)
# Ver las primeras filas de los resultados
head(resultados_prediccion)
# Generación de predicciones
predictTest_logit <- test_factors %>%
mutate(
prob_pobre = predict(mod_2_logit, newdata = test_factors, type = "prob")[,"Yes"],
pred_pobre_cat = predict(mod_2_logit, newdata = test_factors, type = "raw"),
pred_pobre = ifelse(pred_pobre_cat == "Yes", 1, 0)
)
# Distribucion de probabilidades predichas
hist(predictTest_logit$prob_pobre,
main = "Distribución de probabilidades",
xlab = "Probabilidad de ser clasificado como pobre",
col = "lightblue",
border = "white",
breaks = 20)  # Puedes ajustar el número de rangos
# Proporción de clases predichas
prop_clases <- prop.table(table(predictTest_logit$pred_pobre))
print(prop_clases)
# Visualizar proporción de clases en un gráfico de barras
barplot(prop_clases,
main = "Proporción de clases predichas",
xlab = "Clase (0 = No pobre, 1 = Pobre)",
ylab = "Proporción",
col = c("lightgreen", "coral"),
names.arg = c("No pobre", "Pobre"),
ylim = c(0, 1))
# Agregar etiquetas de porcentaje
text(x = 1:length(prop_clases),
y = prop_clases + 0.05,
labels = paste0(round(prop_clases * 100, 1), "%"),
cex = 0.8)
# AHORA puedes guardar solo las columnas necesarias para la entrega
resultados_prediccion <- predictTest_logit %>%
select(id, pred_pobre)
# Ver las primeras filas de los resultados
head(resultados_prediccion)
# Fijar semilla
set.seed(123)
# Resumen de los datos entrenamiento
summary(train_factors)
# Cross validation- entrenamiento fuera de muestra
cv10<- trainControl(number = 5, method ="cv")
# Hiperparámetros
tunegrid_rf<-expand.grid(mtry=c(2,3,4,5, 8), #Predictores aleatorios en cada división                                                del árbol
splitrule= "gini", ##Cambiar por gini y revisar
min.node.size=c(1,2,3,6)) #Tamaño mínimo de los nodos
rforest<-train(Pobre~. ,
data=train_factors,
trControl = cv10,
metric = "RMSE",
tuneGrid = tunegrid_rf,
method ="ranger")
rforest <- train(Pobre~. ,
data = train_factors,
method ="ranger",
trControl = cv10,
metric = "ROC",
tuneGrid = mtry_grid,
ntre = 500
)
# Fijar semilla
set.seed(123)
# Resumen de los datos entrenamiento
summary(train_factors)
# Cross validation- entrenamiento fuera de muestra
cv10<- trainControl(number = 5, method ="cv")
randomforest <- train(Pobre~. ,
data = train_factors,
method ="ranger",
trControl = crossval,
tuneGrid = expand.grid(mtry = 4, splitrule = "gini", min.node.size = 1),
num.trees = 500
)
randomforest <- train(Pobre~. ,
data = train_factors,
method ="ranger",
trControl = crossval,
tuneGrid = expand.grid(mtry = 4, splitrule = "gini", min.node.size = 1),
num.trees = 500
)
# Fijar semilla
set.seed(123)
# Resumen de los datos entrenamiento
summary(train_factors)
# Cross validation- entrenamiento fuera de muestra
crossval<- trainControl(number = 5, method ="cv")
randomforest <- train(Pobre~. ,
data = train_factors,
method ="ranger",
trControl = crossval,
tuneGrid = expand.grid(mtry = 4, splitrule = "gini", min.node.size = 1),
num.trees = 500
)
View(test_factors)
randomforest
# Calcular probabilidades de ser pobre
predictions <- predict(randomforest, newdata = test_factors)
# Criterio de Bayes para clasificación, 1 si es pobre y 0 no es pobre
pred_class <- ifelse(predictions > 0.5, 1, 0)
# Crear una tabla con los valores reales y predichos
tabla_predicciones <- data.frame(
ID = 1:nrow(test_factor),  # Identificador de cada observación
Pobreza_Real = test_factor$pobreza,  # Valores reales de pobreza
Probabilidad_Pobreza = predictions,  # Probabilidad estimada de ser pobre
Pobreza_Predicha = pred_class  # Clasificación final (0 o 1)
)
# Calcular probabilidades de ser pobre
predictions <- predict(randomforest, newdata = test_factors)
# Criterio de Bayes para clasificación, 1 si es pobre y 0 no es pobre
pred_class <- ifelse(predictions > 0.5, 1, 0)
# Crear una tabla con los valores reales y predichos
tabla_predicciones <- data.frame(
ID = 1:nrow(test_factors),  # Identificador de cada observación
Pobreza_Real = test_factors$pobreza,  # Valores reales de pobreza
Probabilidad_Pobreza = predictions,  # Probabilidad estimada de ser pobre
Pobreza_Predicha = pred_class  # Clasificación final (0 o 1)
)
# Calcular probabilidades de ser pobre
predictions <- predict(randomforest, newdata = test_factors, type = "prob")[, 2]
# Calcular probabilidades de ser pobre
predictions <- predict(randomforest, data = test_factors)$predictions[, 2]  # Probabilidad de ser pobre
# 1. Calcular probabilidades de ser pobre
predictions <- predict(randomforest, newdata = test_factors, type = "prob")[, 2]  # Probabilidad de ser pobre
View(randomforest)
#Asignar y cargar las bases de datos Entrenamiento
train_hogares<-read.csv("C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller2/train_hogares.csv")
train_personas<-read.csv("C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller2/train_personas.csv")
#Nombre de las columnas de la base train_hogares
colnames(train_hogares)
#Seleccion de la columnas id de hogares
train_hogares %>%
select(id) %>%
head()
#Cargar los paquetes de trabajo
require("pacman")
p_load(tidyverse, # tidy-data
glmnet, # To implement regularization algorithms.
caret, # creating predictive models
BiocManager,
Metrics
)
install.packages("MLmetrics") # To calculate metrics
require(MLmetrics)
#Seleccion de la columnas id de hogares
train_hogares %>%
select(id) %>%
head()
#Cantidad de hogares probres de la base train_hogares
table(train_hogares$Pobre)
#Incluir una columna con la asignacion de 1 si el ingreso per capita hogar es menor a la linea de probreza y 0 en caso contrario
train_hogares <- train_hogares %>%
mutate(pobre_hand=ifelse(Ingpcug<Lp,1,0))
#Representación en tabla de los resultado
table(train_hogares$Pobre,train_hogares$pobre_hand)
#Nombre de las columnas de la base train_personas
colnames(train_personas)
#Selección de la columnas id y orden de los mienbros de la base personas
train_personas %>%
select(id, Orden) %>%
head()
#Agrupa las personas por hogar y calculo del indicie de personas inactivas
train_personas_1<- train_personas %>%
group_by(id)%>%
summarize(h_inactivos=sum(Ina, na.rm = TRUE),
h_pet=sum(Pet, na.rm = TRUE))%>%
mutate(h_inactivosp=h_inactivos/h_pet) %>%
ungroup()
#Asignar y cargar las bases de datos prueba
test_hogares<-read.csv("C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller2/test_hogares.csv")
test_personas<-read.csv("C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller2/test_personas.csv")
#Nombre de las columnas de la base test_hogares
colnames(test_hogares)
#Selección de la columnas id y número de personas por hogar
test_hogares %>%
select(id, Npersug) %>%
head()
#Nombre de las columnas de la base test_personas
colnames(test_personas)
#Pre procesamiento de la base Train_Personas
clear_train_personas <- train_personas %>%
mutate(mujer = ifelse(P6020==2,1,0),
mayor_edad = ifelse(P6040 >= 18,1,0), #Mayores de edad
H_Head = ifelse(P6050== 1, 1, 0), #Household head
afi_salud = ifelse (P6090==1,1,0), #Afiliacion de salud
afi_salud = ifelse (is.na(afi_salud),0,1), #Reemplazo de los NA
EducLevel = ifelse(P6210==9,0,P6210), #Replace 9 with 0
EducLevel = ifelse(is.na(EducLevel),0,EducLevel),#Reemplazo de los NA
act_semana_pasada = ifelse(P6240 == 6,0,P6240),
act_semana_pasada = ifelse(is.na(act_semana_pasada),0,act_semana_pasada), #Reemplazo de los NA
t_trab_semanal = ifelse(is.na(P6426),0,1),
cotizando = ifelse(P6920 == 3, 1, P6920), #Incluir los pensionados
cotizando = ifelse(is.na(cotizando),0,cotizando),#Reemplazo de los NA
ocupado = ifelse(is.na(Oc),0,1)) %>%
select(id, Orden,mujer,mayor_edad,H_Head,afi_salud,EducLevel,act_semana_pasada,t_trab_semanal,cotizando,ocupado)
#Pre procesamiento de la base Test_Personas
clear_test_personas <- test_personas %>%
mutate(mujer = ifelse(P6020==2,1,0),
mayor_edad = ifelse(P6040 >= 18,1,0), #Mayores de edad
H_Head = ifelse(P6050== 1, 1, 0), #Household head
afi_salud = ifelse (P6090==1,1,0), #Afiliacion de salud
afi_salud = ifelse (is.na(afi_salud),0,1), #Reemplazo de los NA
EducLevel = ifelse(P6210==9,0,P6210), #Replace 9 with 0
EducLevel = ifelse(is.na(EducLevel),0,EducLevel),#Reemplazo de los NA
act_semana_pasada = ifelse(P6240 == 6,0,P6240),
act_semana_pasada = ifelse(is.na(act_semana_pasada),0,act_semana_pasada), #Reemplazo de los NA
t_trab_semanal = ifelse(is.na(P6426),0,1),
cotizando = ifelse(P6920 == 3, 1, P6920), #Incluir los pensionados
cotizando = ifelse(is.na(cotizando),0,cotizando),#Reemplazo de los NA
ocupado = ifelse(is.na(Oc),0,1)) %>%
select(id, Orden,mujer,mayor_edad,H_Head,afi_salud,EducLevel,act_semana_pasada,t_trab_semanal,cotizando,ocupado)
colnames(clear_train_personas)
colnames(clear_test_personas)
#Agrupar el entrenamiento de la base personas a nivel hogar y unir las bases de datos por medio de id.
summary_train_personas_nivel_hogar <- clear_train_personas %>%
group_by(id) %>%
summarize(nmujeres = sum(mujer,na.rm=TRUE),
nmayor_edad = sum(mayor_edad,na.rm=TRUE),
nafi_salud = sum(afi_salud, na.rm = TRUE),
maxEducLevel = max(EducLevel,na.rm=TRUE),
nt_trab_semanal = sum(t_trab_semanal,na.rm = TRUE),
ncotizando = sum(cotizando,na.rm = TRUE),
nocupados=sum(ocupado,na.rm=TRUE))
filter_train_personas_hogar<- clear_train_personas %>%
filter(H_Head==1) %>%
select(id,mujer,afi_salud,EducLevel,cotizando,ocupado) %>%
rename(H_Head_mujer=mujer,
H_afi_salud = afi_salud,
H_Head_Educ_level=EducLevel,
H_cotizando = cotizando,
H_Head_ocupado=ocupado) %>%
left_join(summary_train_personas_nivel_hogar)
colnames(filter_train_personas_hogar)
#Agrupar la prueba de la base personas a nivel hogar y unir las bases de datos por medio de id.
summary_test_personas_nivel_hogar <- clear_test_personas %>%
group_by(id) %>%
summarize(nmujeres = sum(mujer,na.rm=TRUE),
nmayor_edad = sum(mayor_edad,na.rm=TRUE),
nafi_salud = sum(afi_salud, na.rm = TRUE),
maxEducLevel = max(EducLevel,na.rm=TRUE),
nt_trab_semanal = sum(t_trab_semanal,na.rm = TRUE),
ncotizando = sum(cotizando,na.rm = TRUE),
nocupados=sum(ocupado,na.rm=TRUE))
filter_test_personas_hogar<- clear_test_personas %>%
filter(H_Head==1) %>%
select(id,mujer,afi_salud,EducLevel,cotizando,ocupado) %>%
rename(H_Head_mujer=mujer,
H_afi_salud = afi_salud,
H_Head_Educ_level=EducLevel,
H_cotizando = cotizando,
H_Head_ocupado=ocupado) %>%
left_join(summary_test_personas_nivel_hogar, by = "id")
clear_train_hogares<- train_hogares %>%
mutate(pagada= ifelse(P5090==1,1,0),
hipoteca= ifelse(P5090==2,1,0),
arriendo= ifelse(P5090==3,1,0),
usufructo= ifelse(P5090==4,1,0),
sin_titulo = ifelse(P5090==5,1,0)) %>%
select(id, Clase, Nper, Dominio,pagada, hipoteca, arriendo, usufructo, sin_titulo, Lp, Pobre)
clear_test_hogares<- test_hogares %>%
mutate(pagada= ifelse(P5090==1,1,0),
hipoteca= ifelse(P5090==2,1,0),
arriendo= ifelse(P5090==3,1,0),
usufructo= ifelse(P5090==4,1,0),
sin_titulo = ifelse(P5090==5,1,0)) %>%
select(id, Clase, Nper, Dominio, pagada, hipoteca, arriendo, usufructo, sin_titulo, Lp)
clear_test_hogares<- test_hogares %>%
mutate(pagada= ifelse(P5090==1,1,0),
hipoteca= ifelse(P5090==2,1,0),
arriendo= ifelse(P5090==3,1,0),
usufructo= ifelse(P5090==4,1,0),
sin_titulo = ifelse(P5090==5,1,0)) %>%
select(id, Clase, Nper, Dominio, pagada, hipoteca, arriendo, usufructo, sin_titulo, Lp)
train<- clear_train_hogares %>%
left_join(filter_train_personas_hogar) %>%
select(-id) #no longer need id
test<- clear_test_hogares %>%
left_join(filter_test_personas_hogar)
train_factors<- train %>%
mutate(Dominio=factor(Dominio),
pagada=factor(pagada,levels = c(0,1),labels = c("No","Yes")),
hipoteca=factor(hipoteca,levels = c(0,1),labels = c("No","Yes")),
arriendo=factor(arriendo,levels = c(0,1),labels = c("No","Yes")),
usufructo=factor(usufructo,levels = c(0,1),labels = c("No","Yes")),
sin_titulo=factor(sin_titulo,levels = c(0,1),labels = c("No","Yes")),
Pobre=factor(Pobre,levels = c(0,1),labels = c("No", "Yes")),
H_Head_Educ_level = factor(H_Head_Educ_level, levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria')),
maxEducLevel = factor(maxEducLevel,levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria') ))
test_factors<- test %>%
mutate(Dominio=factor(Dominio),
pagada=factor(pagada,levels = c(0,1),labels = c("No","Yes")),
hipoteca=factor(hipoteca,levels = c(0,1),labels = c("No","Yes")),
arriendo=factor(arriendo,levels = c(0,1),labels = c("No","Yes")),
usufructo=factor(usufructo,levels = c(0,1),labels = c("No","Yes")),
sin_titulo=factor(sin_titulo,levels = c(0,1),labels = c("No","Yes")),
H_Head_Educ_level = factor(H_Head_Educ_level, levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria')),
maxEducLevel = factor(maxEducLevel,levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria') ))
randomforest <- randomForest::randomForest(Pobre ~ . ,
data = train_factors,
mtry = 4,  # Valor óptimo encontrado en CV
ntree = 500,  # Número de árboles
importance = TRUE)  # Para ver la importancia de variables
# Ver resultados
print(randomforest)
# Verificar si 'Pobre' falta en test_factors y agregarlo correctamente
if (!("Pobre" %in% names(test_factors))) {
test_factors$Pobre <- factor(NA, levels = levels(train_factors$Pobre))
}
# Asegurar que test_factors tenga todas las variables de train_factors
missing_vars <- setdiff(names(train_factors), names(test_factors))
for (var in missing_vars) {
test_factors[[var]] <- NA
}
# Reordenar columnas para que coincidan
test_factors <- test_factors[, names(train_factors), drop = FALSE]
# Ajustar niveles de factores
for (col in names(test_factors)) {
if (is.factor(train_factors[[col]])) {
test_factors[[col]] <- factor(test_factors[[col]], levels = levels(train_factors[[col]]))
}
}
# Verificar si Pobre ya no es puro NA
table(test_factors$Pobre, useNA = "always")
# Calcular probabilidades (funciona)
test_factors$Pobre <- predict(randomforest, newdata = test_factors)
table(test_factors$Pobre, useNA = "always")
# Fijar semilla
set.seed(123)
control <- trainControl(method = "cv", number = 5)
# Entrenar modelo con CV
modelo_cv <- train(Pobre ~ ., data = train_factors,
method = "rf",
trControl = control,
tuneGrid = data.frame(mtry = 4))
# Fijar semilla
set.seed(123)
control <- trainControl(method = "cv", number = 5)
modelo_rf_cv <- train(Pobre ~ ., data = train_factors,
method = "rf",
trControl = control,
tuneGrid = expand.grid(mtry = 4),
ntree = 500)
# Fijar semilla
set.seed(123)
control <- trainControl(method = "cv", number = 5)
modelo_rf_cv <- train(Pobre ~ ., data = train_factors,
method = "rf",
trControl = control,
tuneGrid = expand.grid(mtry = 4),
ntree = 500)
# Fijar semilla
set.seed(123)
fiveStats <- function(...) {
c(
caret::twoClassSummary(...),  # ROC, Sensibilidad, Especificidad
caret::defaultSummary(...)    # Accuracy y Kappa
)
}
ctrl <- trainControl(
method = "cv",             # cross validation
number = 5,                # 5 folds
summaryFunction = fiveStats,
classProbs = TRUE,         # porque usamos métricas que necesitan probabilidades
verbose = FALSE,
savePredictions = TRUE
)
mtry_grid <- expand.grid(
mtry = 4,
splitrule = "gini",
min.node.size = 1
)
set.seed(123)
cv_rf <- train(
Pobre ~ .,
data = train_factors,
method = "ranger",
metric = "ROC",          # o "Accuracy"
tuneGrid = mtry_grid,
trControl = ctrl,
num.trees = 500
)
print(cv_rf)
rf_pred <- predict(cv_rf, newdata = test_factors, type = "prob")
aucval_rf <- Metrics::auc(
actual = as.numeric(test_factors$Pobre == "Sí"),
predicted = rf_pred[, "Sí"]
)
pred_probs <- predict(cv_rf, newdata = test_factors, type = "prob")
pred_classes <- predict(cv_rf, newdata = test_factors)
# Ver distribución
table(pred_classes)
auc(actual = ifelse(test_factors$Pobre == "Yes", 1, 0),
predicted = pred_probs$Yes)
ranger::importance(cv_rf$finalModel)
roc_obj <- roc(response = test_factors$Pobre,
predictor = pred_probs$Yes)
randomForest::varImpPlot(cv_rf)
table(test_factors$Pobre, useNA = "always")
varImp(cv_rf)
# Predicciones
pred_probs <- predict(cv_rf, newdata = test_factors, type = "prob")
pred_classes <- predict(cv_rf, newdata = test_factors)
table(pred_classes)
auc(actual = ifelse(test_factors$Pobre == "Yes", 1, 0),
predicted = pred_probs$Yes)
# Importancia de variables
plot(varImp(cv_rf), top = 10)
cv_rf$finalModel$variable.importance
randomForest::varImpPlot(randomforest)
# Comparar AUC de ambos modelos
auc_rf <- auc(actual = ifelse(test_factors$Pobre == "Yes", 1, 0),
predicted = rf_pred_probs[, "Yes"])
# Predicciones con randomForest
rf_pred_probs <- predict(randomforest, newdata = test_factors, type = "prob")
rf_pred_classes <- predict(randomforest, newdata = test_factors)
table(rf_pred_classes)
set.seed(123)
cv_rf <- train(
Pobre ~ .,
data = train_factors,
method = "ranger",
metric = "ROC",
tuneGrid = mtry_grid,
trControl = ctrl,
num.trees = 500,
importance = "impurity"  # Para calcular importancia de variables
)
print(cv_rf)
# Predicciones con ranger
ranger_pred_probs <- predict(cv_rf, newdata = test_factors, type = "prob")
ranger_pred_classes <- predict(cv_rf, newdata = test_factors)
table(ranger_pred_classes)
# Comparar AUC de ambos modelos
library(Metrics)
auc_rf <- auc(actual = ifelse(test_factors$Pobre == "Yes", 1, 0),
predicted = rf_pred_probs[, "Yes"])
auc_ranger <- auc(actual = ifelse(test_factors$Pobre == "Yes", 1, 0),
predicted = ranger_pred_probs$Yes)
# Mostrar resultados
print(paste("AUC RandomForest: ", auc_rf))
print(paste("AUC Ranger (CV): ", auc_ranger))
# Ver importancia de variables en ranger
plot(varImp(cv_rf), top = 10)
