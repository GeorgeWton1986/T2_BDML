---
title: "Taller_2"
author: GARCIA BERNAL, ZAIRA ALEJANDRA RIVERA SANABRIA, LAURA SARIF JACOME VELASCO,
  NICOLAS VIAFARA MORALES, JORGE ELIECER
date: "2025-03-22"
output: html_document
---

```{r}
#Cargar los paquetes de trabajo
require("pacman")
p_load(tidyverse, # tidy-data
       glmnet, # To implement regularization algorithms. 
       caret, # creating predictive models
       BiocManager,
       Metrics
)

install.packages("MLmetrics") # To calculate metrics
require(MLmetrics)
```
#A Train 
```{r}
#Asignar y cargar las bases de datos Entrenamiento

train_hogares<-read.csv("C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller2/train_hogares.csv")
train_personas<-read.csv("C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller2/train_personas.csv")

```

##A.1 Base Train Hogares
```{r}
#Nombre de las columnas de la base train_hogares
colnames(train_hogares)
```

```{r}
#Seleccion de la columnas id de hogares
train_hogares %>%
  select(id) %>%
  head()
```

```{r}
#Cantidad de hogares probres de la base train_hogares
table(train_hogares$Pobre)
```

```{r}
#Incluir una columna con la asignacion de 1 si el ingreso per capita hogar es menor a la linea de probreza y 0 en caso contrario
train_hogares <- train_hogares %>% 
  mutate(pobre_hand=ifelse(Ingpcug<Lp,1,0))
```

```{r}
#Representación en tabla de los resultado
table(train_hogares$Pobre,train_hogares$pobre_hand)
```

##A.2 Base Train Personas
```{r}
#Nombre de las columnas de la base train_personas

colnames(train_personas)
```

```{r}
#Selección de la columnas id y orden de los mienbros de la base personas
train_personas %>%
  select(id, Orden) %>%
  head()
```

```{r}
#Agrupa las personas por hogar y calculo del indicie de personas inactivas
train_personas_1<- train_personas %>%
  group_by(id)%>%
  summarize(h_inactivos=sum(Ina, na.rm = TRUE),
            h_pet=sum(Pet, na.rm = TRUE))%>%
  mutate(h_inactivosp=h_inactivos/h_pet) %>%
  ungroup()
```

#B Test
```{r}
#Asignar y cargar las bases de datos prueba

test_hogares<-read.csv("C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller2/test_hogares.csv")
test_personas<-read.csv("C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller2/test_personas.csv")

```

##B.1 Base Test Hogares
```{r}
#Nombre de las columnas de la base test_hogares

colnames(test_hogares)
```

```{r}
#Selección de la columnas id y número de personas por hogar
test_hogares %>%
  select(id, Npersug) %>%
  head()
```


##B.2 Base Test Personas
```{r}
#Nombre de las columnas de la base test_personas

colnames(test_personas)
```

#1. Pre procesamiento

```{r}
#Pre procesamiento de la base Train_Personas
clear_train_personas <- train_personas %>% 
  mutate(mujer = ifelse(P6020==2,1,0),
  mayor_edad = ifelse(P6040 >= 18,1,0), #Mayores de edad
  H_Head = ifelse(P6050== 1, 1, 0), #Household head
  afi_salud = ifelse (P6090==1,1,0), #Afiliacion de salud
  afi_salud = ifelse (is.na(afi_salud),0,1), #Reemplazo de los NA
  EducLevel = ifelse(P6210==9,0,P6210), #Replace 9 with 0
  EducLevel = ifelse(is.na(EducLevel),0,EducLevel),#Reemplazo de los NA
  act_semana_pasada = ifelse(P6240 == 6,0,P6240),
  act_semana_pasada = ifelse(is.na(act_semana_pasada),0,act_semana_pasada), #Reemplazo de los NA
  t_trab_semanal = ifelse(is.na(P6426),0,1),
  cotizando = ifelse(P6920 == 3, 1, P6920), #Incluir los pensionados
  cotizando = ifelse(is.na(cotizando),0,cotizando),#Reemplazo de los NA
  ocupado = ifelse(is.na(Oc),0,1)) %>%
  select(id, Orden,mujer,mayor_edad,H_Head,afi_salud,EducLevel,act_semana_pasada,t_trab_semanal,cotizando,ocupado)

#Pre procesamiento de la base Test_Personas
clear_test_personas <- test_personas %>% 
  mutate(mujer = ifelse(P6020==2,1,0),
  mayor_edad = ifelse(P6040 >= 18,1,0), #Mayores de edad
  H_Head = ifelse(P6050== 1, 1, 0), #Household head
  afi_salud = ifelse (P6090==1,1,0), #Afiliacion de salud
  afi_salud = ifelse (is.na(afi_salud),0,1), #Reemplazo de los NA
  EducLevel = ifelse(P6210==9,0,P6210), #Replace 9 with 0
  EducLevel = ifelse(is.na(EducLevel),0,EducLevel),#Reemplazo de los NA
  act_semana_pasada = ifelse(P6240 == 6,0,P6240),
  act_semana_pasada = ifelse(is.na(act_semana_pasada),0,act_semana_pasada), #Reemplazo de los NA
  t_trab_semanal = ifelse(is.na(P6426),0,1),
  cotizando = ifelse(P6920 == 3, 1, P6920), #Incluir los pensionados
  cotizando = ifelse(is.na(cotizando),0,cotizando),#Reemplazo de los NA
  ocupado = ifelse(is.na(Oc),0,1)) %>%
  select(id, Orden,mujer,mayor_edad,H_Head,afi_salud,EducLevel,act_semana_pasada,t_trab_semanal,cotizando,ocupado)
```

```{r}
colnames(clear_train_personas)
```

```{r}
colnames(clear_test_personas)
```

##1.2 Argupar y unir Train Personas
```{r}
#Agrupar el entrenamiento de la base personas a nivel hogar y unir las bases de datos por medio de id.

summary_train_personas_nivel_hogar <- clear_train_personas %>% 
  group_by(id) %>% 
  summarize(nmujeres = sum(mujer,na.rm=TRUE),
            nmayor_edad = sum(mayor_edad,na.rm=TRUE),
            nafi_salud = sum(afi_salud, na.rm = TRUE),
            maxEducLevel = max(EducLevel,na.rm=TRUE),
            nt_trab_semanal = sum(t_trab_semanal,na.rm = TRUE),
            ncotizando = sum(cotizando,na.rm = TRUE),
            nocupados=sum(ocupado,na.rm=TRUE))

filter_train_personas_hogar<- clear_train_personas %>% 
                  filter(H_Head==1) %>% 
                  select(id,mujer,afi_salud,EducLevel,cotizando,ocupado) %>% 
                  rename(H_Head_mujer=mujer,
                         H_afi_salud = afi_salud,
                         H_Head_Educ_level=EducLevel,
                         H_cotizando = cotizando,
                         H_Head_ocupado=ocupado) %>% 
                    left_join(summary_train_personas_nivel_hogar)
```
```{r}
colnames(filter_train_personas_hogar)
```

##1.3 Agrupar y unir Test Personas
```{r}
#Agrupar la prueba de la base personas a nivel hogar y unir las bases de datos por medio de id.


summary_test_personas_nivel_hogar <- clear_test_personas %>% 
  group_by(id) %>% 
  summarize(nmujeres = sum(mujer,na.rm=TRUE),
            nmayor_edad = sum(mayor_edad,na.rm=TRUE),
            nafi_salud = sum(afi_salud, na.rm = TRUE),
            maxEducLevel = max(EducLevel,na.rm=TRUE),
            nt_trab_semanal = sum(t_trab_semanal,na.rm = TRUE),
            ncotizando = sum(cotizando,na.rm = TRUE),
            nocupados=sum(ocupado,na.rm=TRUE))

filter_test_personas_hogar<- clear_test_personas %>% 
                  filter(H_Head==1) %>% 
                  select(id,mujer,afi_salud,EducLevel,cotizando,ocupado) %>% 
                  rename(H_Head_mujer=mujer,
                         H_afi_salud = afi_salud,
                         H_Head_Educ_level=EducLevel,
                         H_cotizando = cotizando,
                         H_Head_ocupado=ocupado) %>% 
                    left_join(summary_test_personas_nivel_hogar, by = "id")
```
```{r}
colnames(filter_test_personas_hogar)
```
##1.4 Base de trabajo Train Hogares
```{r}
clear_train_hogares<- train_hogares %>% 
  mutate(pagada= ifelse(P5090==1,1,0),
         hipoteca= ifelse(P5090==2,1,0),
         arriendo= ifelse(P5090==3,1,0),
         usufructo= ifelse(P5090==4,1,0),
         sin_titulo = ifelse(P5090==5,1,0)) %>% 
  select(id, Clase, Nper, Dominio,pagada, hipoteca, arriendo, usufructo, sin_titulo, Lp, Pobre)
```

##1.5 Base de trabajo Test Hogares
```{r}
clear_test_hogares<- test_hogares %>% 
  mutate(pagada= ifelse(P5090==1,1,0),
         hipoteca= ifelse(P5090==2,1,0),
         arriendo= ifelse(P5090==3,1,0),
         usufructo= ifelse(P5090==4,1,0),
         sin_titulo = ifelse(P5090==5,1,0)) %>% 
  select(id, Clase, Nper, Dominio, pagada, hipoteca, arriendo, usufructo, sin_titulo, Lp)
```

##1.6 Consolidar las BD Train y Test Hogares
```{r}
train<- clear_train_hogares %>% 
          left_join(filter_train_personas_hogar) %>% 
          select(-id) #no longer need id

test<- clear_test_hogares %>% 
          left_join(filter_test_personas_hogar)

```
##1.7 Conversion a factores
```{r}
train_factors<- train %>% 
  mutate(Dominio=factor(Dominio),
         pagada=factor(pagada,levels = c(0,1),labels = c("No","Yes")),
         hipoteca=factor(hipoteca,levels = c(0,1),labels = c("No","Yes")),
         arriendo=factor(arriendo,levels = c(0,1),labels = c("No","Yes")),
         usufructo=factor(usufructo,levels = c(0,1),labels = c("No","Yes")),
         sin_titulo=factor(sin_titulo,levels = c(0,1),labels = c("No","Yes")),
         Pobre=factor(Pobre,levels = c(0,1),labels = c("No", "Yes")),
         H_Head_Educ_level = factor(H_Head_Educ_level, levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria')),
         maxEducLevel = factor(maxEducLevel,levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria') ))

test_factors<- test %>% 
  mutate(Dominio=factor(Dominio),
         pagada=factor(pagada,levels = c(0,1),labels = c("No","Yes")),
         hipoteca=factor(hipoteca,levels = c(0,1),labels = c("No","Yes")),
         arriendo=factor(arriendo,levels = c(0,1),labels = c("No","Yes")),
         usufructo=factor(usufructo,levels = c(0,1),labels = c("No","Yes")),
         sin_titulo=factor(sin_titulo,levels = c(0,1),labels = c("No","Yes")),
         H_Head_Educ_level = factor(H_Head_Educ_level, levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria')),
         maxEducLevel = factor(maxEducLevel,levels = c(0:6),labels = c("Ns",'Ninguno', 'Preescolar','Primaria', 'Secundaria','Media', 'Universitaria') ))

```

#2. Entrenamiento Modelo Elastic Net

##2.1 Modelo Elastic Net
```{r}

ctrl<- trainControl(method = "cv",
                    number = 5,
                    classProbs = TRUE,
                    savePredictions = T)
```

```{r}
#Modelo Elastic Net

set.seed(123)

mod_1_EN <- train(Pobre~.,#Modelo 1 Elastic Net
    data=train_factors,
    metric = "Accuracy",
    method = "glmnet",
    trControl = ctrl,
    tuneGrid=expand.grid(
              alpha = seq(0,1,by=.2),
              lambda =10^seq(10, -2, length = 10)
    )
               
)
```
##2.2 Resultado_EN
```{r}
mod_1_EN
```
##2.2 Modelo F1
```{r}
p_load(Metrics)
fiveStats <- function(...)  c(prSummary(...))  


ctrl<- trainControl(method = "cv",
                    number = 5,
                    classProbs = TRUE,
                    summaryFunction = fiveStats,
                    savePredictions = TRUE)
```

```{r}

set.seed(123)
mod_1_F <- train(Pobre~.,
    data=train_factors,
    metric = "F",
    method = "glmnet",
    trControl = ctrl,
    family="binomial",
    tuneGrid=expand.grid(
              alpha = seq(0,1,by=.5),
              lambda =10^seq(-1, -3, length = 10)
    )

)
```
##2.4 Resultado_F1
```{r}
mod_1_F
```
#3. Entrenamiento Modelo Logit

##3.1 Estimadores logit
```{r}
#Calculo de los estimadores Logit
mod_1_logit<- glm(Pobre~., 
                 data = train_factors, 
                 family = "binomial")

```

##3.2 Resultados Estimadores Logit 
```{r}
summary(mod_1_logit,type="text")
```

##3.3 Probabilidad Logit
```{r}
#Calculo de probabilidades
prob_logit<- train_factors %>% 
  mutate(prob_hat=predict(mod_1_logit,
                          newdata = train_factors, 
                          type = "response"))


```

## 3.4 Resultado Probabilidad Logit
```{r}
head(prob_logit %>% 
       select(Pobre,prob_hat))
```

## 3.5 Clasificador Logit
```{r}

rule <- 0.4 # Bayes Rule

prob_logit<- prob_logit %>% 
  mutate(pred_pobre=ifelse(prob_hat>rule,1,0))    ## prediccion de pobre (0) No pobre y (1) Pobre

head(prob_logit %>%
       select(Pobre,prob_hat,pred_pobre))

```

##3.6.1 Matriz de confusion
```{r}
# Convertir la variable Pred_pobre a factor con etiquetas descriptivas
prob_logit$pred_pobre_factor <- factor(prob_logit$pred_pobre,
                                      levels = c(0, 1),
                                      labels = c("No Pobre", "Pobre"))

#Creacion de una matriz de confuncion
#           Predicho
# Real       0    1
#       0   [TN] [FP]
#       1   [FN] [TP]

#Matriz de confusión
A <- with(prob_logit,table(Pobre,pred_pobre_factor))

# Mostrar matriz de confusión
print("Matriz de confusión:")
print(A)

# Explicacion de valores matriz de confusion
TN_train <- A[1]  # Verdaderos Negativos
FP_train <- A[2]  # Falsos Positivos
FN_train <- A[3]  # Falsos Negativos
TP_train <- A[4]  # Verdaderos Positivos

# Crear tabla de conteos
counts_table <- data.frame(
  Categoría = c("Verdaderos Negativos (TN)", "Falsos Positivos (FP)", 
                "Falsos Negativos (FN)", "Verdaderos Positivos (TP)"),
  Conteo = c(TN_train, FP_train, FN_train, TP_train)
)

print(counts_table)


```

##3.6.2 Metricas Modelo Logit
```{r}
#Métricas derivadas:
# Exactitud (Accuracy): (TP + TN) / (TP + TN + FP + FN)
# Proporción de predicciones correctas.
# Precisión (Precision): TP / (TP + FP)
# De todos los casos predichos como "Pobres", ¿cuántos realmente lo son?
# Sensibilidad/Recall: TP / (TP + FN)
# De todos los casos realmente "Pobres", ¿cuántos identificamos correctamente?
# Especificidad: TN / (TN + FP)
# De todos los casos realmente "No pobres", ¿cuántos identificamos correctamente?
# F1-Score: 2 * (Precisión * Recall) / (Precisión + Recall)
# Media armónica de precisión y recall.

# Accuracy
accuracy_train <- (TN_train+ TP_train) / (TN_train + FP_train + FN_train + TP_train)
# Precisión
precision_train <- TP_train / (TP_train + FP_train)
# Recall (Sensibilidad)
recall_train <- TP_train / (TP_train + FN_train)
# Especificidad
specificity_train <- TN_train / (TN_train + FP_train)
# F1 Score
f1_score_train <- 2 * (precision_train * recall_train) / (precision_train + recall_train)
# Error Rate (Tasa de error)
error_rate_train <- 1 - accuracy_train


# Crear tabla de métricas
metrics_table_mod_1_log <- data.frame(
  metrica_train = c("Accuracy (Exactitud)", "Precision (Precisión)", "Recall (Sensibilidad)", 
              "Specificity (Especificidad)", "F1 Score", "Error Rate (Tasa de error)"),
  Valor = c(accuracy_train, precision_train, recall_train, specificity_train, f1_score_train, error_rate_train),
  Descripción = c(
    "Proporción total de predicciones correctas",
    "De los predichos como pobres, cuántos realmente lo son",
    "De los realmente pobres, cuántos fueron identificados correctamente",
    "De los realmente no pobres, cuántos fueron identificados correctamente",
    "Media armónica entre precisión y recall",
    "Proporción de predicciones incorrectas"
  )
)

# Mostrar tabla
print(metrics_table_mod_1_log)

```

##3.7 Entrenamiento Fuera de muestra Modelo_Logit
```{r}
ctrl<- trainControl(method = "cv",
                    number = 5,
                    classProbs = TRUE,
                    savePredictions = TRUE,
                    verbose=T
                    )
```

##3.8 Entrenamiento modelo 2
```{r}
set.seed(123)
mod_2_logit <- train(Pobre~. ,
                     data = train_factors, 
                     method = "glm",
                     family = "binomial",
                     trControl = ctrl,
                     metric = "Accuracy"
                     )

# Ver resultados
print(mod_2_logit)
summary(mod_2_logit)

# Ver predicciones por cada fold
head(mod_2_logit$pred)

```

##3.9 Matriz de confusion modelo 2
```{r}
#Matriz de confusion del modelo de entrenamiento
B <- confusionMatrix(mod_2_logit)

B <- B$table

# Explicacion de valores matriz de confusion
TN_train_cv <- B[1,1]  # Verdaderos Negativos
FP_train_cv <- B[2,1]  # Falsos Positivos
FN_train_cv <- B[1,2]  # Falsos Negativos
TP_train_cv <- B[2,2]  # Verdaderos Positivos

# Calcular métricas
accuracy_train_cv <- (TN_train_cv + TP_train_cv) / (TN_train_cv + FP_train_cv + FN_train_cv + TP_train_cv)
precision_train_cv <- TP_train_cv / (TP_train_cv + FP_train_cv)
recall_train_cv <- TP_train_cv / (TP_train_cv + FN_train_cv)
specificity_train_cv <- TN_train_cv / (TN_train_cv + FP_train_cv)
f1_score_train_cv <- 2 * (precision_train_cv * recall_train_cv) / (precision_train_cv + recall_train_cv)
error_rate_train_cv <- 1 - accuracy_train_cv

# Crear un data frame con los resultados
metrics_table_mod_2_log <- data.frame(
  metrica_train_cv = c("Accuracy (Exactitud)", "Precision (Precisión)", "Recall (Sensibilidad)", 
              "Specificity (Especificidad)", "F1 Score", "Error Rate (Tasa de error)"),
  Valor = c(accuracy_train_cv, precision_train_cv, recall_train_cv, specificity_train_cv, f1_score_train_cv, error_rate_train_cv)
)

print(metrics_table_mod_2_log)
```

##3.10 Explorar la importancia de las variables
```{r}
# Importancia de variables
importancia <- varImp(mod_2_logit, scale = TRUE)
print(importancia)
plot(importancia, top = 20, main = "Las variables más importantes")
```

##3.11 Predición con el Test Set/Clasificacion 
```{r}
#Prediccion el Test Set
predictTest_logit <- test_factors %>% 
  mutate(
    prob_pobre = predict(mod_2_logit, 
                         newdata = test_factors, 
                         type = "prob")[,"Yes"],# Probabilidad de ser "Pobre" ("Yes")
    pred_pobre_cat = predict(mod_2_logit, 
                             newdata = test_factors, 
                             type = "raw"), # Predicción categórica (Yes/No)
    pred_pobre = ifelse(pred_pobre_cat == "Yes", 1, 0)# Predicción numérica (1/0)
  )

# Resumen
summary(predictTest_logit$prob_pobre)
table(predictTest_logit$pred_pobre_cat)
table(predictTest_logit$pred_pobre)

# Guardar los resultados
resultados_prediccion<- predictTest_logit %>%
  select(id, pred_pobre)

# Ver las primeras filas de los resultados
head(resultados_prediccion)

```

##3.12 Gráficos de la predicción
```{r}
# Generación de predicciones
predictTest_logit <- test_factors %>% 
  mutate(
    prob_pobre = predict(mod_2_logit, newdata = test_factors, type = "prob")[,"Yes"],
    pred_pobre_cat = predict(mod_2_logit, newdata = test_factors, type = "raw"),
    pred_pobre = ifelse(pred_pobre_cat == "Yes", 1, 0)
  )

# Distribucion de probabilidades predichas
hist(predictTest_logit$prob_pobre, 
     main = "Distribución de probabilidades", 
     xlab = "Probabilidad de ser clasificado como pobre",
     col = "lightblue",
     border = "white",
     breaks = 20)  # Puedes ajustar el número de rangos

# Proporción de clases predichas
prop_clases <- prop.table(table(predictTest_logit$pred_pobre))
print(prop_clases)

# Visualizar proporción de clases en un gráfico de barras
barplot(prop_clases,
        main = "Proporción de clases predichas",
        xlab = "Clase (0 = No pobre, 1 = Pobre)",
        ylab = "Proporción",
        col = c("lightgreen", "coral"),
        names.arg = c("No pobre", "Pobre"),
        ylim = c(0, 1))

# Agregar etiquetas de porcentaje
text(x = 1:length(prop_clases), 
     y = prop_clases + 0.05,
     labels = paste0(round(prop_clases * 100, 1), "%"),
     cex = 0.8)

# AHORA puedes guardar solo las columnas necesarias para la entrega
resultados_prediccion <- predictTest_logit %>%
  select(id, pred_pobre)

# Ver las primeras filas de los resultados
head(resultados_prediccion)
```

##3.12 Template_Logit
```{r}
write.csv(resultados_prediccion, "/Users/jorgeviafara/Library/CloudStorage/OneDrive-Personal/MAESTRIA EN ECONOMIA/01 MATERIAS MECA/4107 BIG DATA/T2_BDML_personal/01042025sample_equipo4_Logit.csv", row.names = FALSE)
```

#3 Predicciones

##3.1 Predicción_EN
```{r}

predictSample_EN <- test_factors   %>% 
  mutate(pobre_lab = predict(mod_1_EN, 
                             newdata = test_factors, 
                             type = "raw"))%>% 
  select(id,pobre_lab)

head(predictSample_EN)

```

```{r}
predictSample_EN<- predictSample_EN %>% 
                  mutate(pobre=ifelse(pobre_lab=="Yes",1,0)) %>% 
                  select(id,pobre)
head(predictSample_EN) 
```

```{r}
nrow(predictSample_EN)
str(predictSample_EN)
head(predictSample_EN)
```

##3.2 Template_EN
```{r}
write.csv(predictSample_EN, "/Users/jorgeviafara/Library/CloudStorage/OneDrive-Personal/MAESTRIA EN ECONOMIA/01 MATERIAS MECA/4107 BIG DATA/T2_BDML_personal/sample_equipo4_EN.csv", row.names = FALSE)

```

```{r}
str(predictSample_EN)  # Verifica estructura
summary(predictSample_EN)  # Estadísticas básicas
head(predictSample_EN, 10)  # Muestra las primeras 10 filas
```

# 4. Entrenamiento Ramdon Forest

## 4.1 Entrenamiento fuera de muestra Random Forest
```{r}
# Fijar semilla
set.seed(123)

# Resumen de los datos entrenamiento
summary(train_factors)

# Cross validation- entrenamiento fuera de muestra
crossval<- trainControl(number = 5, method ="cv")

```

## 4.2 Entrenamiento modelo Random Forest
```{r}
randomforest <- train(Pobre~. ,
               data = train_factors, 
               method ="ranger",
               trControl = crossval,
              tuneGrid = expand.grid(mtry = 4, splitrule = "gini", min.node.size = 1),  
              num.trees = 500  
              )
randomforest

```
## 4.3 Predicción con el test set de Random Forest
```{r}
# 1. Calcular probabilidades de ser pobre
predictions <- predict(randomforest, newdata = test_factors, type = "prob")[, 2]  # Probabilidad de ser pobre
predictions
# # 2. Convertir probabilidades en 0 o 1 (pobreza predicha)
# pred_class <- ifelse(predictions > 0.5, 1, 0)
# 
# # 3. Crear tabla con predicciones
# tabla_predicciones <- data.frame(
#   ID = 1:nrow(test_factors),  
#   Probabilidad_Pobreza = predictions,  
#   Pobreza_Predicha = pred_class  
# )
# 
# # 4. Mostrar las primeras 10 filas de la tabla de predicciones
# head(tabla_predicciones, 10)

```

#



```{r}
#  Evaluar el modelo: Precisión (Accuracy)
accuracy <- mean(pred_class == test_factor$Default)
print(paste("Precisión del modelo:", round(accuracy * 100, 2), "%"))

# Si es regresión, calcular el Error Medio Absoluto (MAE)
mae <- mean(abs(predictions - test_factor$Default))
print(paste("Error Medio Absoluto:", round(mae, 2)))
```

